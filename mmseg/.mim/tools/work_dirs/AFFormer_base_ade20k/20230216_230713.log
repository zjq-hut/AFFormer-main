2023-02-16 23:07:13,277 - mmseg - INFO - OpenCV num_threads is `<built-in function getNumThreads>
2023-02-16 23:07:15,568 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: win32
Python: 3.8.10 (default, May 19 2021, 13:12:57) [MSC v.1916 64 bit (AMD64)]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3060 Laptop GPU
CUDA_HOME: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1
NVCC: Cuda compilation tools, release 11.1, V11.1.105
MSVC: 用于 x64 的 Microsoft (R) C/C++ 优化编译器 19.29.30138 版
GCC: n/a
PyTorch: 1.8.0+cu111
PyTorch compiling details: PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)
  - OpenMP 2019
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -DNDEBUG -DUSE_FBGEMM -DUSE_XNNPACK, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

TorchVision: 0.9.0+cu111
OpenCV: 4.6.0
MMCV: 1.5.0
MMCV Compiler: MSVC 192930138
MMCV CUDA Compiler: 11.1
MMSegmentation: 0.21.1+
------------------------------------------------------------

2023-02-16 23:07:15,584 - mmseg - INFO - Distributed training: False
2023-02-16 23:07:15,756 - mmseg - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
ham_norm_cfg = dict(type='GN', num_groups=32, requires_grad=True)
model = dict(
    type='EncoderDecoder',
    pretrained=
    'E:/5.23/2.13-2.20/2.15/AFFormer-main/pretained_weight/AFFormer_base_ImageNet1k.pth',
    backbone=dict(type='afformer_base', strides=[4, 2, 2, 2]),
    decode_head=dict(
        type='CLS',
        in_channels=[216],
        in_index=[3],
        channels=256,
        aff_channels=256,
        dropout_ratio=0.1,
        num_classes=150,
        norm_cfg=dict(type='GN', num_groups=32, requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),
        aff_kwargs=dict(MD_R=16)),
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'ADE20KDataset'
data_root = 'G:/AI/data/ade20k'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (256, 256)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=True),
    dict(type='Resize', img_scale=(256, 256), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(256, 256), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(256, 256), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
val_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(256, 256),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(256, 256),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='ResizeToMultiple', size_divisor=32),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=8,
    workers_per_gpu=8,
    train=dict(
        type='RepeatDataset',
        times=1,
        dataset=dict(
            type='ADE20KDataset',
            data_root='G:/AI/data/ade20k',
            img_dir='images/training',
            ann_dir='annotations/training',
            pipeline=[
                dict(type='LoadImageFromFile'),
                dict(type='LoadAnnotations', reduce_zero_label=True),
                dict(
                    type='Resize',
                    img_scale=(256, 256),
                    ratio_range=(0.5, 2.0)),
                dict(
                    type='RandomCrop',
                    crop_size=(256, 256),
                    cat_max_ratio=0.75),
                dict(type='RandomFlip', prob=0.5),
                dict(type='PhotoMetricDistortion'),
                dict(
                    type='Normalize',
                    mean=[123.675, 116.28, 103.53],
                    std=[58.395, 57.12, 57.375],
                    to_rgb=True),
                dict(type='Pad', size=(256, 256), pad_val=0, seg_pad_val=255),
                dict(type='DefaultFormatBundle'),
                dict(type='Collect', keys=['img', 'gt_semantic_seg'])
            ])),
    val=dict(
        type='ADE20KDataset',
        data_root='G:/AI/data/ade20k',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(256, 256),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='ADE20KDataset',
        data_root='G:/AI/data/ade20k',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(256, 256),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='ResizeToMultiple', size_divisor=32),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(
    type='AdamW', lr=0.0003, betas=(0.9, 0.999), weight_decay=0.01)
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06,
    power=1.0,
    min_lr=0.0,
    by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=160000)
checkpoint_config = dict(by_epoch=False, interval=16000)
evaluation = dict(interval=5000, metric='mIoU', pre_eval=True)
find_unused_parameters = True
work_dir = './work_dirs\AFFormer_base_ade20k'
gpu_ids = [0]
auto_resume = False

2023-02-16 23:07:15,756 - mmseg - INFO - Set random seed to 920553579, deterministic: False
2023-02-16 23:07:15,802 - mmseg - INFO - load checkpoint from local path: E:/5.23/2.13-2.20/2.15/AFFormer-main/pretained_weight/AFFormer_base_ImageNet1k.pth
2023-02-16 23:07:15,866 - mmseg - WARNING - The model and loaded state dict do not match exactly

size mismatch for stem.0.conv.weight: copying a param with shape torch.Size([32, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 3, 3, 3]).
size mismatch for stem.0.bn.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).
size mismatch for stem.0.bn.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).
size mismatch for stem.0.bn.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).
size mismatch for stem.0.bn.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).
size mismatch for stem.1.conv.weight: copying a param with shape torch.Size([64, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 16, 3, 3]).
size mismatch for stem.1.bn.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for stem.1.bn.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for stem.1.bn.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for stem.1.bn.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for patch_embed_stages.0.patch_embeds.0.patch_conv.dwconv.weight: copying a param with shape torch.Size([64, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 1, 3, 3]).
size mismatch for patch_embed_stages.0.patch_embeds.0.patch_conv.pwconv.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 1]).
size mismatch for patch_embed_stages.0.patch_embeds.0.patch_conv.bn.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for patch_embed_stages.0.patch_embeds.0.patch_conv.bn.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for patch_embed_stages.0.patch_embeds.0.patch_conv.bn.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for patch_embed_stages.0.patch_embeds.0.patch_conv.bn.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for patch_embed_stages.0.patch_embeds.1.patch_conv.dwconv.weight: copying a param with shape torch.Size([64, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 1, 3, 3]).
size mismatch for patch_embed_stages.0.patch_embeds.1.patch_conv.pwconv.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 1]).
size mismatch for patch_embed_stages.0.patch_embeds.1.patch_conv.bn.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for patch_embed_stages.0.patch_embeds.1.patch_conv.bn.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for patch_embed_stages.0.patch_embeds.1.patch_conv.bn.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for patch_embed_stages.0.patch_embeds.1.patch_conv.bn.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for mhca_stages.0.Restore.conv1.conv.weight: copying a param with shape torch.Size([32, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([16, 32, 1, 1]).
size mismatch for mhca_stages.0.Restore.conv1.bn.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).
size mismatch for mhca_stages.0.Restore.conv1.bn.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).
size mismatch for mhca_stages.0.Restore.conv1.bn.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).
size mismatch for mhca_stages.0.Restore.conv1.bn.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).
size mismatch for mhca_stages.0.Restore.dwconv.weight: copying a param with shape torch.Size([32, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 1, 3, 3]).
size mismatch for mhca_stages.0.Restore.norm.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).
size mismatch for mhca_stages.0.Restore.norm.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).
size mismatch for mhca_stages.0.Restore.norm.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).
size mismatch for mhca_stages.0.Restore.norm.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).
size mismatch for mhca_stages.0.Restore.conv2.conv.weight: copying a param with shape torch.Size([64, 32, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 16, 1, 1]).
size mismatch for mhca_stages.0.Restore.conv2.bn.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for mhca_stages.0.Restore.conv2.bn.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for mhca_stages.0.Restore.conv2.bn.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for mhca_stages.0.Restore.conv2.bn.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for mhca_stages.0.aggregate.conv.weight: copying a param with shape torch.Size([96, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([96, 32, 1, 1]).
size mismatch for mhca_stages.1.aggregate.conv.weight: copying a param with shape torch.Size([176, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([176, 96, 1, 1]).
size mismatch for mhca_stages.2.aggregate.conv.weight: copying a param with shape torch.Size([216, 352, 1, 1]) from checkpoint, the shape in current model is torch.Size([216, 176, 1, 1]).
size mismatch for mhca_stages.3.aggregate.conv.weight: copying a param with shape torch.Size([216, 432, 1, 1]) from checkpoint, the shape in current model is torch.Size([216, 216, 1, 1]).
unexpected key in source state_dict: cls_head.cls.weight, cls_head.cls.bias

missing keys in source state_dict: mhca_stages.2.mhca_blks.0.MHCA_layers.4.cpe.proj.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.cpe.proj.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.4.crpe.conv_list.0.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.crpe.conv_list.0.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.4.crpe.conv_list.1.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.crpe.conv_list.1.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.4.crpe.conv_list.2.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.crpe.conv_list.2.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.qkv.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.qkv.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.proj.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.proj.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.crpe.conv_list.0.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.crpe.conv_list.0.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.crpe.conv_list.1.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.crpe.conv_list.1.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.crpe.conv_list.2.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.crpe.conv_list.2.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.4.mlp.fc1.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.mlp.fc1.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.4.mlp.dwconv.dwconv.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.mlp.dwconv.dwconv.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.4.mlp.fc2.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.mlp.fc2.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.4.norm1.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.norm1.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.4.norm2.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.norm2.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.cpe.proj.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.cpe.proj.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.crpe.conv_list.0.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.crpe.conv_list.0.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.crpe.conv_list.1.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.crpe.conv_list.1.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.crpe.conv_list.2.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.crpe.conv_list.2.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.qkv.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.qkv.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.proj.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.proj.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.crpe.conv_list.0.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.crpe.conv_list.0.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.crpe.conv_list.1.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.crpe.conv_list.1.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.crpe.conv_list.2.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.crpe.conv_list.2.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.mlp.fc1.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.mlp.fc1.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.mlp.dwconv.dwconv.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.mlp.dwconv.dwconv.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.mlp.fc2.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.mlp.fc2.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.norm1.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.norm1.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.norm2.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.norm2.bias

2023-02-16 23:07:15,882 - mmseg - INFO - initialize CLS with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
Name of parameter - Initialization information

backbone.stem.0.conv.weight - torch.Size([16, 3, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.0.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.0.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.1.conv.weight - torch.Size([32, 16, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.1.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.1.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed_stages.0.patch_embeds.0.patch_conv.dwconv.weight - torch.Size([32, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed_stages.0.patch_embeds.0.patch_conv.pwconv.weight - torch.Size([32, 32, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed_stages.0.patch_embeds.0.patch_conv.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed_stages.0.patch_embeds.0.patch_conv.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed_stages.0.patch_embeds.1.patch_conv.dwconv.weight - torch.Size([32, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed_stages.0.patch_embeds.1.patch_conv.pwconv.weight - torch.Size([32, 32, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed_stages.0.patch_embeds.1.patch_conv.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed_stages.0.patch_embeds.1.patch_conv.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed_stages.1.patch_embeds.0.patch_conv.dwconv.weight - torch.Size([96, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.1.patch_embeds.0.patch_conv.pwconv.weight - torch.Size([96, 96, 1, 1]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.1.patch_embeds.0.patch_conv.bn.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.1.patch_embeds.0.patch_conv.bn.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.1.patch_embeds.1.patch_conv.dwconv.weight - torch.Size([96, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.1.patch_embeds.1.patch_conv.pwconv.weight - torch.Size([96, 96, 1, 1]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.1.patch_embeds.1.patch_conv.bn.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.1.patch_embeds.1.patch_conv.bn.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.2.patch_embeds.0.patch_conv.dwconv.weight - torch.Size([176, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.2.patch_embeds.0.patch_conv.pwconv.weight - torch.Size([176, 176, 1, 1]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.2.patch_embeds.0.patch_conv.bn.weight - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.2.patch_embeds.0.patch_conv.bn.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.2.patch_embeds.1.patch_conv.dwconv.weight - torch.Size([176, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.2.patch_embeds.1.patch_conv.pwconv.weight - torch.Size([176, 176, 1, 1]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.2.patch_embeds.1.patch_conv.bn.weight - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.2.patch_embeds.1.patch_conv.bn.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.3.patch_embeds.0.patch_conv.dwconv.weight - torch.Size([216, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.3.patch_embeds.0.patch_conv.pwconv.weight - torch.Size([216, 216, 1, 1]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.3.patch_embeds.0.patch_conv.bn.weight - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.3.patch_embeds.0.patch_conv.bn.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.3.patch_embeds.1.patch_conv.dwconv.weight - torch.Size([216, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.3.patch_embeds.1.patch_conv.pwconv.weight - torch.Size([216, 216, 1, 1]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.3.patch_embeds.1.patch_conv.bn.weight - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.3.patch_embeds.1.patch_conv.bn.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.0.Restore.conv1.conv.weight - torch.Size([16, 32, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.0.Restore.conv1.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.0.Restore.conv1.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.0.Restore.dwconv.weight - torch.Size([16, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.0.Restore.norm.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.0.Restore.norm.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.0.Restore.conv2.conv.weight - torch.Size([32, 16, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.0.Restore.conv2.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.0.Restore.conv2.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.0.aggregate.conv.weight - torch.Size([96, 32, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.0.aggregate.bn.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.0.aggregate.bn.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.Restore.conv1.conv.weight - torch.Size([48, 96, 1, 1]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.Restore.conv1.bn.weight - torch.Size([48]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.Restore.conv1.bn.bias - torch.Size([48]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.Restore.dwconv.weight - torch.Size([48, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.Restore.norm.weight - torch.Size([48]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.Restore.norm.bias - torch.Size([48]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.Restore.conv2.conv.weight - torch.Size([96, 48, 1, 1]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.Restore.conv2.bn.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.Restore.conv2.bn.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.aggregate.conv.weight - torch.Size([176, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.1.aggregate.bn.weight - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.aggregate.bn.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.cpe.proj.weight - torch.Size([96, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.cpe.proj.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.crpe.conv_list.0.weight - torch.Size([24, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.crpe.conv_list.0.bias - torch.Size([24]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.crpe.conv_list.1.weight - torch.Size([36, 1, 5, 5]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.crpe.conv_list.1.bias - torch.Size([36]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.crpe.conv_list.2.weight - torch.Size([36, 1, 7, 7]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.crpe.conv_list.2.bias - torch.Size([36]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.factoratt_crpe.qkv.weight - torch.Size([288, 96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.factoratt_crpe.qkv.bias - torch.Size([288]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.factoratt_crpe.proj.weight - torch.Size([96, 96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.factoratt_crpe.proj.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.mlp.fc1.weight - torch.Size([192, 96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.mlp.fc1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.mlp.dwconv.dwconv.weight - torch.Size([192, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.mlp.dwconv.dwconv.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.mlp.fc2.weight - torch.Size([96, 192]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.mlp.fc2.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.norm1.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.norm1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.norm2.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.norm2.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.factoratt_crpe.qkv.weight - torch.Size([288, 96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.factoratt_crpe.qkv.bias - torch.Size([288]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.factoratt_crpe.proj.weight - torch.Size([96, 96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.factoratt_crpe.proj.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.mlp.fc1.weight - torch.Size([192, 96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.mlp.fc1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.mlp.dwconv.dwconv.weight - torch.Size([192, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.mlp.dwconv.dwconv.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.mlp.fc2.weight - torch.Size([96, 192]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.mlp.fc2.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.norm1.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.norm1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.norm2.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.norm2.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.Restore.conv1.conv.weight - torch.Size([88, 176, 1, 1]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.Restore.conv1.bn.weight - torch.Size([88]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.Restore.conv1.bn.bias - torch.Size([88]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.Restore.dwconv.weight - torch.Size([88, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.Restore.norm.weight - torch.Size([88]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.Restore.norm.bias - torch.Size([88]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.Restore.conv2.conv.weight - torch.Size([176, 88, 1, 1]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.Restore.conv2.bn.weight - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.Restore.conv2.bn.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.aggregate.conv.weight - torch.Size([216, 176, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.aggregate.bn.weight - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.aggregate.bn.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.cpe.proj.weight - torch.Size([176, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.cpe.proj.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.crpe.conv_list.0.weight - torch.Size([44, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.crpe.conv_list.0.bias - torch.Size([44]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.crpe.conv_list.1.weight - torch.Size([66, 1, 5, 5]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.crpe.conv_list.1.bias - torch.Size([66]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.crpe.conv_list.2.weight - torch.Size([66, 1, 7, 7]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.crpe.conv_list.2.bias - torch.Size([66]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.factoratt_crpe.qkv.weight - torch.Size([528, 176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.factoratt_crpe.qkv.bias - torch.Size([528]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.factoratt_crpe.proj.weight - torch.Size([176, 176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.factoratt_crpe.proj.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.mlp.fc1.weight - torch.Size([352, 176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.mlp.fc1.bias - torch.Size([352]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.mlp.dwconv.dwconv.weight - torch.Size([352, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.mlp.dwconv.dwconv.bias - torch.Size([352]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.mlp.fc2.weight - torch.Size([176, 352]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.mlp.fc2.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.norm1.weight - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.norm1.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.norm2.weight - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.norm2.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.factoratt_crpe.qkv.weight - torch.Size([528, 176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.factoratt_crpe.qkv.bias - torch.Size([528]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.factoratt_crpe.proj.weight - torch.Size([176, 176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.factoratt_crpe.proj.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.mlp.fc1.weight - torch.Size([352, 176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.mlp.fc1.bias - torch.Size([352]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.mlp.dwconv.dwconv.weight - torch.Size([352, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.mlp.dwconv.dwconv.bias - torch.Size([352]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.mlp.fc2.weight - torch.Size([176, 352]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.mlp.fc2.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.norm1.weight - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.norm1.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.norm2.weight - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.norm2.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.factoratt_crpe.qkv.weight - torch.Size([528, 176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.factoratt_crpe.qkv.bias - torch.Size([528]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.factoratt_crpe.proj.weight - torch.Size([176, 176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.factoratt_crpe.proj.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.mlp.fc1.weight - torch.Size([352, 176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.mlp.fc1.bias - torch.Size([352]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.mlp.dwconv.dwconv.weight - torch.Size([352, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.mlp.dwconv.dwconv.bias - torch.Size([352]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.mlp.fc2.weight - torch.Size([176, 352]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.mlp.fc2.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.norm1.weight - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.norm1.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.norm2.weight - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.norm2.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.factoratt_crpe.qkv.weight - torch.Size([528, 176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.factoratt_crpe.qkv.bias - torch.Size([528]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.factoratt_crpe.proj.weight - torch.Size([176, 176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.factoratt_crpe.proj.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.mlp.fc1.weight - torch.Size([352, 176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.mlp.fc1.bias - torch.Size([352]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.mlp.dwconv.dwconv.weight - torch.Size([352, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.mlp.dwconv.dwconv.bias - torch.Size([352]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.mlp.fc2.weight - torch.Size([176, 352]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.mlp.fc2.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.norm1.weight - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.norm1.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.norm2.weight - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.norm2.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.qkv.weight - torch.Size([528, 176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.qkv.bias - torch.Size([528]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.proj.weight - torch.Size([176, 176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.proj.bias - torch.Size([176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.mlp.fc1.weight - torch.Size([352, 176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.mlp.fc1.bias - torch.Size([352]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.mlp.dwconv.dwconv.weight - torch.Size([352, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.mlp.dwconv.dwconv.bias - torch.Size([352]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.mlp.fc2.weight - torch.Size([176, 352]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.mlp.fc2.bias - torch.Size([176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.norm1.weight - torch.Size([176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.norm1.bias - torch.Size([176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.norm2.weight - torch.Size([176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.norm2.bias - torch.Size([176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.qkv.weight - torch.Size([528, 176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.qkv.bias - torch.Size([528]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.proj.weight - torch.Size([176, 176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.proj.bias - torch.Size([176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.mlp.fc1.weight - torch.Size([352, 176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.mlp.fc1.bias - torch.Size([352]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.mlp.dwconv.dwconv.weight - torch.Size([352, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.mlp.dwconv.dwconv.bias - torch.Size([352]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.mlp.fc2.weight - torch.Size([176, 352]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.mlp.fc2.bias - torch.Size([176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.norm1.weight - torch.Size([176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.norm1.bias - torch.Size([176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.norm2.weight - torch.Size([176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.norm2.bias - torch.Size([176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.3.Restore.conv1.conv.weight - torch.Size([108, 216, 1, 1]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.Restore.conv1.bn.weight - torch.Size([108]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.Restore.conv1.bn.bias - torch.Size([108]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.Restore.dwconv.weight - torch.Size([108, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.Restore.norm.weight - torch.Size([108]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.Restore.norm.bias - torch.Size([108]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.Restore.conv2.conv.weight - torch.Size([216, 108, 1, 1]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.Restore.conv2.bn.weight - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.Restore.conv2.bn.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.aggregate.conv.weight - torch.Size([216, 216, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.3.aggregate.bn.weight - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.aggregate.bn.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.cpe.proj.weight - torch.Size([216, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.cpe.proj.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.crpe.conv_list.0.weight - torch.Size([54, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.crpe.conv_list.0.bias - torch.Size([54]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.crpe.conv_list.1.weight - torch.Size([81, 1, 5, 5]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.crpe.conv_list.1.bias - torch.Size([81]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.crpe.conv_list.2.weight - torch.Size([81, 1, 7, 7]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.crpe.conv_list.2.bias - torch.Size([81]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.factoratt_crpe.qkv.weight - torch.Size([648, 216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.factoratt_crpe.qkv.bias - torch.Size([648]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.factoratt_crpe.proj.weight - torch.Size([216, 216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.factoratt_crpe.proj.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.mlp.fc1.weight - torch.Size([432, 216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.mlp.fc1.bias - torch.Size([432]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.mlp.dwconv.dwconv.weight - torch.Size([432, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.mlp.dwconv.dwconv.bias - torch.Size([432]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.mlp.fc2.weight - torch.Size([216, 432]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.mlp.fc2.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.norm1.weight - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.norm1.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.norm2.weight - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.norm2.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.factoratt_crpe.qkv.weight - torch.Size([648, 216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.factoratt_crpe.qkv.bias - torch.Size([648]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.factoratt_crpe.proj.weight - torch.Size([216, 216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.factoratt_crpe.proj.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.mlp.fc1.weight - torch.Size([432, 216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.mlp.fc1.bias - torch.Size([432]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.mlp.dwconv.dwconv.weight - torch.Size([432, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.mlp.dwconv.dwconv.bias - torch.Size([432]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.mlp.fc2.weight - torch.Size([216, 432]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.mlp.fc2.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.norm1.weight - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.norm1.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.norm2.weight - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.norm2.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

decode_head.conv_seg.weight - torch.Size([150, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([150]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.squeeze.conv.weight - torch.Size([256, 216, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.squeeze.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.squeeze.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.align.conv.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.align.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.align.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2023-02-16 23:07:15,882 - mmseg - INFO - EncoderDecoder(
  (backbone): afformer_base(
    (stem): Sequential(
      (0): Conv2d_BN(
        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act_layer): Hardswish()
      )
      (1): Conv2d_BN(
        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act_layer): Hardswish()
      )
    )
    (patch_embed_stages): ModuleList(
      (0): Patch_Embed_stage(
        (patch_embeds): ModuleList(
          (0): DWCPatchEmbed(
            (patch_conv): DWConv2d_BN(
              (dwconv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
              (pwconv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Hardswish()
            )
          )
          (1): DWCPatchEmbed(
            (patch_conv): DWConv2d_BN(
              (dwconv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
              (pwconv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Hardswish()
            )
          )
        )
      )
      (1): Patch_Embed_stage(
        (patch_embeds): ModuleList(
          (0): DWCPatchEmbed(
            (patch_conv): DWConv2d_BN(
              (dwconv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
              (pwconv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Hardswish()
            )
          )
          (1): DWCPatchEmbed(
            (patch_conv): DWConv2d_BN(
              (dwconv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (pwconv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Hardswish()
            )
          )
        )
      )
      (2): Patch_Embed_stage(
        (patch_embeds): ModuleList(
          (0): DWCPatchEmbed(
            (patch_conv): DWConv2d_BN(
              (dwconv): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176, bias=False)
              (pwconv): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Hardswish()
            )
          )
          (1): DWCPatchEmbed(
            (patch_conv): DWConv2d_BN(
              (dwconv): Conv2d(176, 176, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=176, bias=False)
              (pwconv): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Hardswish()
            )
          )
        )
      )
      (3): Patch_Embed_stage(
        (patch_embeds): ModuleList(
          (0): DWCPatchEmbed(
            (patch_conv): DWConv2d_BN(
              (dwconv): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)
              (pwconv): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Hardswish()
            )
          )
          (1): DWCPatchEmbed(
            (patch_conv): DWConv2d_BN(
              (dwconv): Conv2d(216, 216, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=216, bias=False)
              (pwconv): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Hardswish()
            )
          )
        )
      )
    )
    (mhca_stages): ModuleList(
      (0): MHCA_stage(
        (Restore): Restore(
          (conv1): Conv2d_BN(
            (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_layer): Hardswish()
          )
          (dwconv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
          (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Hardswish()
          (conv2): Conv2d_BN(
            (conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_layer): Identity()
          )
        )
        (aggregate): Conv2d_BN(
          (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_layer): Hardswish()
        )
      )
      (1): MHCA_stage(
        (Restore): Restore(
          (conv1): Conv2d_BN(
            (conv): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_layer): Hardswish()
          )
          (dwconv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
          (norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Hardswish()
          (conv2): Conv2d_BN(
            (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_layer): Identity()
          )
        )
        (aggregate): Conv2d_BN(
          (conv): Conv2d(96, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_layer): Hardswish()
        )
        (mhca_blks): ModuleList(
          (0): MHCAEncoder(
            (cpe): ConvPosEnc(
              (proj): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
            )
            (crpe): FilterModule(
              (conv_list): ModuleList(
                (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
                (1): Conv2d(36, 36, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=36)
                (2): Conv2d(36, 36, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=36)
              )
              (LP): LowPassModule(
                (stages): ModuleList(
                  (0): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=(1, 1))
                  )
                  (1): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=(2, 2))
                  )
                  (2): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=(3, 3))
                  )
                  (3): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=(6, 6))
                  )
                )
                (relu): ReLU()
              )
            )
            (MHCA_layers): ModuleList(
              (0): MHCABlock(
                (cpe): ConvPosEnc(
                  (proj): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
                )
                (crpe): FilterModule(
                  (conv_list): ModuleList(
                    (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
                    (1): Conv2d(36, 36, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=36)
                    (2): Conv2d(36, 36, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=36)
                  )
                  (LP): LowPassModule(
                    (stages): ModuleList(
                      (0): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(1, 1))
                      )
                      (1): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(2, 2))
                      )
                      (2): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(3, 3))
                      )
                      (3): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(6, 6))
                      )
                    )
                    (relu): ReLU()
                  )
                )
                (factoratt_crpe): Frequency_FilterModule(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (crpe): FilterModule(
                    (conv_list): ModuleList(
                      (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
                      (1): Conv2d(36, 36, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=36)
                      (2): Conv2d(36, 36, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=36)
                    )
                    (LP): LowPassModule(
                      (stages): ModuleList(
                        (0): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(1, 1))
                        )
                        (1): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(2, 2))
                        )
                        (2): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(3, 3))
                        )
                        (3): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(6, 6))
                        )
                      )
                      (relu): ReLU()
                    )
                  )
                )
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=192, bias=True)
                  (dwconv): DWConv(
                    (dwconv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
                  )
                  (act): GELU()
                  (fc2): Linear(in_features=192, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (drop_path): Identity()
                (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
                (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
              )
              (1): MHCABlock(
                (cpe): ConvPosEnc(
                  (proj): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
                )
                (crpe): FilterModule(
                  (conv_list): ModuleList(
                    (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
                    (1): Conv2d(36, 36, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=36)
                    (2): Conv2d(36, 36, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=36)
                  )
                  (LP): LowPassModule(
                    (stages): ModuleList(
                      (0): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(1, 1))
                      )
                      (1): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(2, 2))
                      )
                      (2): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(3, 3))
                      )
                      (3): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(6, 6))
                      )
                    )
                    (relu): ReLU()
                  )
                )
                (factoratt_crpe): Frequency_FilterModule(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (crpe): FilterModule(
                    (conv_list): ModuleList(
                      (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
                      (1): Conv2d(36, 36, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=36)
                      (2): Conv2d(36, 36, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=36)
                    )
                    (LP): LowPassModule(
                      (stages): ModuleList(
                        (0): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(1, 1))
                        )
                        (1): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(2, 2))
                        )
                        (2): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(3, 3))
                        )
                        (3): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(6, 6))
                        )
                      )
                      (relu): ReLU()
                    )
                  )
                )
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=192, bias=True)
                  (dwconv): DWConv(
                    (dwconv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
                  )
                  (act): GELU()
                  (fc2): Linear(in_features=192, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (drop_path): Identity()
                (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
                (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
              )
            )
          )
        )
      )
      (2): MHCA_stage(
        (Restore): Restore(
          (conv1): Conv2d_BN(
            (conv): Conv2d(176, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_layer): Hardswish()
          )
          (dwconv): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)
          (norm): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Hardswish()
          (conv2): Conv2d_BN(
            (conv): Conv2d(88, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_layer): Identity()
          )
        )
        (aggregate): Conv2d_BN(
          (conv): Conv2d(176, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_layer): Hardswish()
        )
        (mhca_blks): ModuleList(
          (0): MHCAEncoder(
            (cpe): ConvPosEnc(
              (proj): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176)
            )
            (crpe): FilterModule(
              (conv_list): ModuleList(
                (0): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=44)
                (1): Conv2d(66, 66, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=66)
                (2): Conv2d(66, 66, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=66)
              )
              (LP): LowPassModule(
                (stages): ModuleList(
                  (0): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=(1, 1))
                  )
                  (1): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=(2, 2))
                  )
                  (2): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=(3, 3))
                  )
                  (3): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=(6, 6))
                  )
                )
                (relu): ReLU()
              )
            )
            (MHCA_layers): ModuleList(
              (0): MHCABlock(
                (cpe): ConvPosEnc(
                  (proj): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176)
                )
                (crpe): FilterModule(
                  (conv_list): ModuleList(
                    (0): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=44)
                    (1): Conv2d(66, 66, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=66)
                    (2): Conv2d(66, 66, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=66)
                  )
                  (LP): LowPassModule(
                    (stages): ModuleList(
                      (0): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(1, 1))
                      )
                      (1): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(2, 2))
                      )
                      (2): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(3, 3))
                      )
                      (3): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(6, 6))
                      )
                    )
                    (relu): ReLU()
                  )
                )
                (factoratt_crpe): Frequency_FilterModule(
                  (qkv): Linear(in_features=176, out_features=528, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=176, out_features=176, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (crpe): FilterModule(
                    (conv_list): ModuleList(
                      (0): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=44)
                      (1): Conv2d(66, 66, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=66)
                      (2): Conv2d(66, 66, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=66)
                    )
                    (LP): LowPassModule(
                      (stages): ModuleList(
                        (0): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(1, 1))
                        )
                        (1): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(2, 2))
                        )
                        (2): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(3, 3))
                        )
                        (3): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(6, 6))
                        )
                      )
                      (relu): ReLU()
                    )
                  )
                )
                (mlp): Mlp(
                  (fc1): Linear(in_features=176, out_features=352, bias=True)
                  (dwconv): DWConv(
                    (dwconv): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352)
                  )
                  (act): GELU()
                  (fc2): Linear(in_features=352, out_features=176, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (drop_path): Identity()
                (norm1): LayerNorm((176,), eps=1e-06, elementwise_affine=True)
                (norm2): LayerNorm((176,), eps=1e-06, elementwise_affine=True)
              )
              (1): MHCABlock(
                (cpe): ConvPosEnc(
                  (proj): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176)
                )
                (crpe): FilterModule(
                  (conv_list): ModuleList(
                    (0): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=44)
                    (1): Conv2d(66, 66, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=66)
                    (2): Conv2d(66, 66, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=66)
                  )
                  (LP): LowPassModule(
                    (stages): ModuleList(
                      (0): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(1, 1))
                      )
                      (1): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(2, 2))
                      )
                      (2): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(3, 3))
                      )
                      (3): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(6, 6))
                      )
                    )
                    (relu): ReLU()
                  )
                )
                (factoratt_crpe): Frequency_FilterModule(
                  (qkv): Linear(in_features=176, out_features=528, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=176, out_features=176, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (crpe): FilterModule(
                    (conv_list): ModuleList(
                      (0): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=44)
                      (1): Conv2d(66, 66, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=66)
                      (2): Conv2d(66, 66, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=66)
                    )
                    (LP): LowPassModule(
                      (stages): ModuleList(
                        (0): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(1, 1))
                        )
                        (1): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(2, 2))
                        )
                        (2): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(3, 3))
                        )
                        (3): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(6, 6))
                        )
                      )
                      (relu): ReLU()
                    )
                  )
                )
                (mlp): Mlp(
                  (fc1): Linear(in_features=176, out_features=352, bias=True)
                  (dwconv): DWConv(
                    (dwconv): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352)
                  )
                  (act): GELU()
                  (fc2): Linear(in_features=352, out_features=176, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (drop_path): Identity()
                (norm1): LayerNorm((176,), eps=1e-06, elementwise_affine=True)
                (norm2): LayerNorm((176,), eps=1e-06, elementwise_affine=True)
              )
              (2): MHCABlock(
                (cpe): ConvPosEnc(
                  (proj): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176)
                )
                (crpe): FilterModule(
                  (conv_list): ModuleList(
                    (0): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=44)
                    (1): Conv2d(66, 66, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=66)
                    (2): Conv2d(66, 66, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=66)
                  )
                  (LP): LowPassModule(
                    (stages): ModuleList(
                      (0): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(1, 1))
                      )
                      (1): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(2, 2))
                      )
                      (2): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(3, 3))
                      )
                      (3): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(6, 6))
                      )
                    )
                    (relu): ReLU()
                  )
                )
                (factoratt_crpe): Frequency_FilterModule(
                  (qkv): Linear(in_features=176, out_features=528, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=176, out_features=176, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (crpe): FilterModule(
                    (conv_list): ModuleList(
                      (0): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=44)
                      (1): Conv2d(66, 66, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=66)
                      (2): Conv2d(66, 66, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=66)
                    )
                    (LP): LowPassModule(
                      (stages): ModuleList(
                        (0): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(1, 1))
                        )
                        (1): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(2, 2))
                        )
                        (2): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(3, 3))
                        )
                        (3): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(6, 6))
                        )
                      )
                      (relu): ReLU()
                    )
                  )
                )
                (mlp): Mlp(
                  (fc1): Linear(in_features=176, out_features=352, bias=True)
                  (dwconv): DWConv(
                    (dwconv): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352)
                  )
                  (act): GELU()
                  (fc2): Linear(in_features=352, out_features=176, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (drop_path): Identity()
                (norm1): LayerNorm((176,), eps=1e-06, elementwise_affine=True)
                (norm2): LayerNorm((176,), eps=1e-06, elementwise_affine=True)
              )
              (3): MHCABlock(
                (cpe): ConvPosEnc(
                  (proj): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176)
                )
                (crpe): FilterModule(
                  (conv_list): ModuleList(
                    (0): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=44)
                    (1): Conv2d(66, 66, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=66)
                    (2): Conv2d(66, 66, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=66)
                  )
                  (LP): LowPassModule(
                    (stages): ModuleList(
                      (0): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(1, 1))
                      )
                      (1): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(2, 2))
                      )
                      (2): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(3, 3))
                      )
                      (3): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(6, 6))
                      )
                    )
                    (relu): ReLU()
                  )
                )
                (factoratt_crpe): Frequency_FilterModule(
                  (qkv): Linear(in_features=176, out_features=528, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=176, out_features=176, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (crpe): FilterModule(
                    (conv_list): ModuleList(
                      (0): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=44)
                      (1): Conv2d(66, 66, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=66)
                      (2): Conv2d(66, 66, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=66)
                    )
                    (LP): LowPassModule(
                      (stages): ModuleList(
                        (0): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(1, 1))
                        )
                        (1): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(2, 2))
                        )
                        (2): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(3, 3))
                        )
                        (3): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(6, 6))
                        )
                      )
                      (relu): ReLU()
                    )
                  )
                )
                (mlp): Mlp(
                  (fc1): Linear(in_features=176, out_features=352, bias=True)
                  (dwconv): DWConv(
                    (dwconv): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352)
                  )
                  (act): GELU()
                  (fc2): Linear(in_features=352, out_features=176, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (drop_path): Identity()
                (norm1): LayerNorm((176,), eps=1e-06, elementwise_affine=True)
                (norm2): LayerNorm((176,), eps=1e-06, elementwise_affine=True)
              )
              (4): MHCABlock(
                (cpe): ConvPosEnc(
                  (proj): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176)
                )
                (crpe): FilterModule(
                  (conv_list): ModuleList(
                    (0): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=44)
                    (1): Conv2d(66, 66, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=66)
                    (2): Conv2d(66, 66, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=66)
                  )
                  (LP): LowPassModule(
                    (stages): ModuleList(
                      (0): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(1, 1))
                      )
                      (1): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(2, 2))
                      )
                      (2): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(3, 3))
                      )
                      (3): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(6, 6))
                      )
                    )
                    (relu): ReLU()
                  )
                )
                (factoratt_crpe): Frequency_FilterModule(
                  (qkv): Linear(in_features=176, out_features=528, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=176, out_features=176, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (crpe): FilterModule(
                    (conv_list): ModuleList(
                      (0): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=44)
                      (1): Conv2d(66, 66, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=66)
                      (2): Conv2d(66, 66, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=66)
                    )
                    (LP): LowPassModule(
                      (stages): ModuleList(
                        (0): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(1, 1))
                        )
                        (1): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(2, 2))
                        )
                        (2): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(3, 3))
                        )
                        (3): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(6, 6))
                        )
                      )
                      (relu): ReLU()
                    )
                  )
                )
                (mlp): Mlp(
                  (fc1): Linear(in_features=176, out_features=352, bias=True)
                  (dwconv): DWConv(
                    (dwconv): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352)
                  )
                  (act): GELU()
                  (fc2): Linear(in_features=352, out_features=176, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (drop_path): Identity()
                (norm1): LayerNorm((176,), eps=1e-06, elementwise_affine=True)
                (norm2): LayerNorm((176,), eps=1e-06, elementwise_affine=True)
              )
              (5): MHCABlock(
                (cpe): ConvPosEnc(
                  (proj): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176)
                )
                (crpe): FilterModule(
                  (conv_list): ModuleList(
                    (0): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=44)
                    (1): Conv2d(66, 66, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=66)
                    (2): Conv2d(66, 66, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=66)
                  )
                  (LP): LowPassModule(
                    (stages): ModuleList(
                      (0): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(1, 1))
                      )
                      (1): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(2, 2))
                      )
                      (2): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(3, 3))
                      )
                      (3): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(6, 6))
                      )
                    )
                    (relu): ReLU()
                  )
                )
                (factoratt_crpe): Frequency_FilterModule(
                  (qkv): Linear(in_features=176, out_features=528, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=176, out_features=176, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (crpe): FilterModule(
                    (conv_list): ModuleList(
                      (0): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=44)
                      (1): Conv2d(66, 66, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=66)
                      (2): Conv2d(66, 66, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=66)
                    )
                    (LP): LowPassModule(
                      (stages): ModuleList(
                        (0): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(1, 1))
                        )
                        (1): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(2, 2))
                        )
                        (2): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(3, 3))
                        )
                        (3): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(6, 6))
                        )
                      )
                      (relu): ReLU()
                    )
                  )
                )
                (mlp): Mlp(
                  (fc1): Linear(in_features=176, out_features=352, bias=True)
                  (dwconv): DWConv(
                    (dwconv): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352)
                  )
                  (act): GELU()
                  (fc2): Linear(in_features=352, out_features=176, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (drop_path): Identity()
                (norm1): LayerNorm((176,), eps=1e-06, elementwise_affine=True)
                (norm2): LayerNorm((176,), eps=1e-06, elementwise_affine=True)
              )
            )
          )
        )
      )
      (3): MHCA_stage(
        (Restore): Restore(
          (conv1): Conv2d_BN(
            (conv): Conv2d(216, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_layer): Hardswish()
          )
          (dwconv): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=108, bias=False)
          (norm): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Hardswish()
          (conv2): Conv2d_BN(
            (conv): Conv2d(108, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_layer): Identity()
          )
        )
        (aggregate): Conv2d_BN(
          (conv): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_layer): Hardswish()
        )
        (mhca_blks): ModuleList(
          (0): MHCAEncoder(
            (cpe): ConvPosEnc(
              (proj): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216)
            )
            (crpe): FilterModule(
              (conv_list): ModuleList(
                (0): Conv2d(54, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=54)
                (1): Conv2d(81, 81, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=81)
                (2): Conv2d(81, 81, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=81)
              )
              (LP): LowPassModule(
                (stages): ModuleList(
                  (0): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=(1, 1))
                  )
                  (1): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=(2, 2))
                  )
                  (2): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=(3, 3))
                  )
                  (3): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=(6, 6))
                  )
                )
                (relu): ReLU()
              )
            )
            (MHCA_layers): ModuleList(
              (0): MHCABlock(
                (cpe): ConvPosEnc(
                  (proj): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216)
                )
                (crpe): FilterModule(
                  (conv_list): ModuleList(
                    (0): Conv2d(54, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=54)
                    (1): Conv2d(81, 81, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=81)
                    (2): Conv2d(81, 81, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=81)
                  )
                  (LP): LowPassModule(
                    (stages): ModuleList(
                      (0): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(1, 1))
                      )
                      (1): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(2, 2))
                      )
                      (2): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(3, 3))
                      )
                      (3): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(6, 6))
                      )
                    )
                    (relu): ReLU()
                  )
                )
                (factoratt_crpe): Frequency_FilterModule(
                  (qkv): Linear(in_features=216, out_features=648, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=216, out_features=216, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (crpe): FilterModule(
                    (conv_list): ModuleList(
                      (0): Conv2d(54, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=54)
                      (1): Conv2d(81, 81, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=81)
                      (2): Conv2d(81, 81, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=81)
                    )
                    (LP): LowPassModule(
                      (stages): ModuleList(
                        (0): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(1, 1))
                        )
                        (1): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(2, 2))
                        )
                        (2): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(3, 3))
                        )
                        (3): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(6, 6))
                        )
                      )
                      (relu): ReLU()
                    )
                  )
                )
                (mlp): Mlp(
                  (fc1): Linear(in_features=216, out_features=432, bias=True)
                  (dwconv): DWConv(
                    (dwconv): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432)
                  )
                  (act): GELU()
                  (fc2): Linear(in_features=432, out_features=216, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (drop_path): Identity()
                (norm1): LayerNorm((216,), eps=1e-06, elementwise_affine=True)
                (norm2): LayerNorm((216,), eps=1e-06, elementwise_affine=True)
              )
              (1): MHCABlock(
                (cpe): ConvPosEnc(
                  (proj): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216)
                )
                (crpe): FilterModule(
                  (conv_list): ModuleList(
                    (0): Conv2d(54, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=54)
                    (1): Conv2d(81, 81, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=81)
                    (2): Conv2d(81, 81, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=81)
                  )
                  (LP): LowPassModule(
                    (stages): ModuleList(
                      (0): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(1, 1))
                      )
                      (1): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(2, 2))
                      )
                      (2): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(3, 3))
                      )
                      (3): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(6, 6))
                      )
                    )
                    (relu): ReLU()
                  )
                )
                (factoratt_crpe): Frequency_FilterModule(
                  (qkv): Linear(in_features=216, out_features=648, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=216, out_features=216, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (crpe): FilterModule(
                    (conv_list): ModuleList(
                      (0): Conv2d(54, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=54)
                      (1): Conv2d(81, 81, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=81)
                      (2): Conv2d(81, 81, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=81)
                    )
                    (LP): LowPassModule(
                      (stages): ModuleList(
                        (0): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(1, 1))
                        )
                        (1): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(2, 2))
                        )
                        (2): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(3, 3))
                        )
                        (3): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(6, 6))
                        )
                      )
                      (relu): ReLU()
                    )
                  )
                )
                (mlp): Mlp(
                  (fc1): Linear(in_features=216, out_features=432, bias=True)
                  (dwconv): DWConv(
                    (dwconv): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432)
                  )
                  (act): GELU()
                  (fc2): Linear(in_features=432, out_features=216, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (drop_path): Identity()
                (norm1): LayerNorm((216,), eps=1e-06, elementwise_affine=True)
                (norm2): LayerNorm((216,), eps=1e-06, elementwise_affine=True)
              )
            )
          )
        )
      )
    )
  )
  init_cfg=E:/5.23/2.13-2.20/2.15/AFFormer-main/pretained_weight/AFFormer_base_ImageNet1k.pth
  (decode_head): CLS(
    input_transform=multiple_select, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss()
    (conv_seg): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (squeeze): ConvModule(
      (conv): Conv2d(216, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (gn): GroupNorm(32, 256, eps=1e-05, affine=True)
      (activate): ReLU(inplace=True)
    )
    (align): ConvModule(
      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (gn): GroupNorm(32, 256, eps=1e-05, affine=True)
      (activate): ReLU(inplace=True)
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
)
2023-02-16 23:07:15,913 - mmseg - INFO - Loaded 960 images
2023-02-16 23:07:17,249 - mmseg - INFO - Loaded 88 images
2023-02-16 23:07:17,249 - mmseg - INFO - Start running, host: 赵家琪@LAPTOP-1ADKIJ7N, work_dir: E:\5.23\2.13-2.20\2.15\AFFormer-main\tools\work_dirs\AFFormer_base_ade20k
2023-02-16 23:07:17,249 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-02-16 23:07:17,249 - mmseg - INFO - workflow: [('train', 1)], max: 160000 iters
2023-02-16 23:07:17,249 - mmseg - INFO - Checkpoints will be saved to E:\5.23\2.13-2.20\2.15\AFFormer-main\tools\work_dirs\AFFormer_base_ade20k by HardDiskBackend.
2023-02-16 23:07:42,514 - mmseg - INFO - Iter [50/160000]	lr: 9.797e-06, eta: 9:03:16, time: 0.204, data_time: 0.006, memory: 1942, decode.loss_ce: 3.6473, decode.acc_seg: 0.3122, loss: 3.6473
2023-02-16 23:07:50,345 - mmseg - INFO - Iter [100/160000]	lr: 1.979e-05, eta: 8:00:15, time: 0.157, data_time: 0.006, memory: 1942, decode.loss_ce: 3.6360, decode.acc_seg: 2.3132, loss: 3.6360
2023-02-16 23:08:00,411 - mmseg - INFO - Iter [150/160000]	lr: 2.977e-05, eta: 8:18:51, time: 0.201, data_time: 0.050, memory: 1942, decode.loss_ce: 3.6382, decode.acc_seg: 14.7995, loss: 3.6382
2023-02-16 23:08:08,115 - mmseg - INFO - Iter [200/160000]	lr: 3.975e-05, eta: 7:56:37, time: 0.154, data_time: 0.006, memory: 1942, decode.loss_ce: 3.4081, decode.acc_seg: 25.9557, loss: 3.4081
2023-02-16 23:08:18,213 - mmseg - INFO - Iter [250/160000]	lr: 4.972e-05, eta: 8:08:42, time: 0.202, data_time: 0.048, memory: 1942, decode.loss_ce: 3.1676, decode.acc_seg: 26.0016, loss: 3.1676
2023-02-16 23:08:25,936 - mmseg - INFO - Iter [300/160000]	lr: 5.969e-05, eta: 7:55:39, time: 0.154, data_time: 0.004, memory: 1942, decode.loss_ce: 2.7874, decode.acc_seg: 36.0997, loss: 2.7874
2023-02-16 23:08:33,674 - mmseg - INFO - Iter [350/160000]	lr: 6.965e-05, eta: 7:46:24, time: 0.155, data_time: 0.006, memory: 1942, decode.loss_ce: 2.5376, decode.acc_seg: 27.4634, loss: 2.5376
2023-02-16 23:08:43,564 - mmseg - INFO - Iter [400/160000]	lr: 7.960e-05, eta: 7:53:38, time: 0.197, data_time: 0.047, memory: 1942, decode.loss_ce: 2.3947, decode.acc_seg: 34.5432, loss: 2.3947
2023-02-16 23:08:51,247 - mmseg - INFO - Iter [450/160000]	lr: 8.955e-05, eta: 7:46:16, time: 0.154, data_time: 0.006, memory: 1942, decode.loss_ce: 2.1707, decode.acc_seg: 30.9928, loss: 2.1707
2023-02-16 23:09:01,157 - mmseg - INFO - Iter [500/160000]	lr: 9.949e-05, eta: 7:52:12, time: 0.198, data_time: 0.047, memory: 1942, decode.loss_ce: 2.1543, decode.acc_seg: 32.9912, loss: 2.1543
2023-02-16 23:09:08,828 - mmseg - INFO - Iter [550/160000]	lr: 1.094e-04, eta: 7:46:12, time: 0.153, data_time: 0.005, memory: 1942, decode.loss_ce: 1.8003, decode.acc_seg: 38.6845, loss: 1.8003
2023-02-16 23:09:16,527 - mmseg - INFO - Iter [600/160000]	lr: 1.194e-04, eta: 7:41:18, time: 0.154, data_time: 0.005, memory: 1942, decode.loss_ce: 2.0915, decode.acc_seg: 30.5662, loss: 2.0915
2023-02-16 23:09:26,594 - mmseg - INFO - Iter [650/160000]	lr: 1.293e-04, eta: 7:46:50, time: 0.201, data_time: 0.049, memory: 1942, decode.loss_ce: 1.9071, decode.acc_seg: 38.6565, loss: 1.9071
2023-02-16 23:09:34,526 - mmseg - INFO - Iter [700/160000]	lr: 1.392e-04, eta: 7:43:26, time: 0.159, data_time: 0.006, memory: 1942, decode.loss_ce: 1.9214, decode.acc_seg: 36.2875, loss: 1.9214
2023-02-16 23:09:44,544 - mmseg - INFO - Iter [750/160000]	lr: 1.491e-04, eta: 7:47:51, time: 0.200, data_time: 0.049, memory: 1942, decode.loss_ce: 1.9935, decode.acc_seg: 35.2777, loss: 1.9935
2023-02-16 23:09:52,360 - mmseg - INFO - Iter [800/160000]	lr: 1.590e-04, eta: 7:44:24, time: 0.156, data_time: 0.006, memory: 1942, decode.loss_ce: 1.8514, decode.acc_seg: 41.3673, loss: 1.8514
2023-02-16 23:10:02,338 - mmseg - INFO - Iter [850/160000]	lr: 1.689e-04, eta: 7:48:04, time: 0.200, data_time: 0.051, memory: 1942, decode.loss_ce: 1.9759, decode.acc_seg: 34.1696, loss: 1.9759
2023-02-16 23:10:10,072 - mmseg - INFO - Iter [900/160000]	lr: 1.788e-04, eta: 7:44:43, time: 0.155, data_time: 0.007, memory: 1942, decode.loss_ce: 1.6883, decode.acc_seg: 43.1292, loss: 1.6883
2023-02-16 23:10:17,948 - mmseg - INFO - Iter [950/160000]	lr: 1.887e-04, eta: 7:42:06, time: 0.158, data_time: 0.006, memory: 1942, decode.loss_ce: 1.8830, decode.acc_seg: 35.8360, loss: 1.8830
2023-02-16 23:10:27,886 - mmseg - INFO - Exp name: AFFormer_base_ade20k.py
2023-02-16 23:10:27,886 - mmseg - INFO - Iter [1000/160000]	lr: 1.986e-04, eta: 7:45:11, time: 0.199, data_time: 0.049, memory: 1942, decode.loss_ce: 1.9474, decode.acc_seg: 36.7789, loss: 1.9474
2023-02-16 23:10:35,674 - mmseg - INFO - Iter [1050/160000]	lr: 2.084e-04, eta: 7:42:33, time: 0.156, data_time: 0.006, memory: 1942, decode.loss_ce: 1.7696, decode.acc_seg: 42.5969, loss: 1.7696
2023-02-16 23:10:45,682 - mmseg - INFO - Iter [1100/160000]	lr: 2.183e-04, eta: 7:45:29, time: 0.200, data_time: 0.049, memory: 1942, decode.loss_ce: 1.9615, decode.acc_seg: 36.8951, loss: 1.9615
2023-02-16 23:10:53,407 - mmseg - INFO - Iter [1150/160000]	lr: 2.281e-04, eta: 7:42:53, time: 0.155, data_time: 0.007, memory: 1942, decode.loss_ce: 1.5334, decode.acc_seg: 49.9485, loss: 1.5334
2023-02-16 23:11:01,279 - mmseg - INFO - Iter [1200/160000]	lr: 2.380e-04, eta: 7:40:47, time: 0.157, data_time: 0.006, memory: 1942, decode.loss_ce: 1.9596, decode.acc_seg: 34.8376, loss: 1.9596
2023-02-16 23:11:11,145 - mmseg - INFO - Iter [1250/160000]	lr: 2.479e-04, eta: 7:43:08, time: 0.198, data_time: 0.051, memory: 1942, decode.loss_ce: 1.7857, decode.acc_seg: 43.1338, loss: 1.7857
2023-02-16 23:11:18,883 - mmseg - INFO - Iter [1300/160000]	lr: 2.577e-04, eta: 7:40:55, time: 0.155, data_time: 0.006, memory: 1942, decode.loss_ce: 1.8160, decode.acc_seg: 41.9883, loss: 1.8160
2023-02-16 23:11:28,892 - mmseg - INFO - Iter [1350/160000]	lr: 2.675e-04, eta: 7:43:19, time: 0.200, data_time: 0.048, memory: 1942, decode.loss_ce: 1.8674, decode.acc_seg: 37.8800, loss: 1.8674
2023-02-16 23:11:36,729 - mmseg - INFO - Iter [1400/160000]	lr: 2.774e-04, eta: 7:41:25, time: 0.157, data_time: 0.008, memory: 1942, decode.loss_ce: 1.6178, decode.acc_seg: 48.2619, loss: 1.6178

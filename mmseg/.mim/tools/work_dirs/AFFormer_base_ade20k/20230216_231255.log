2023-02-16 23:12:55,255 - mmseg - INFO - OpenCV num_threads is `<built-in function getNumThreads>
2023-02-16 23:13:06,321 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: win32
Python: 3.8.10 (default, May 19 2021, 13:12:57) [MSC v.1916 64 bit (AMD64)]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3060 Laptop GPU
CUDA_HOME: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1
NVCC: Cuda compilation tools, release 11.1, V11.1.105
MSVC: 用于 x64 的 Microsoft (R) C/C++ 优化编译器 19.29.30138 版
GCC: n/a
PyTorch: 1.8.0+cu111
PyTorch compiling details: PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)
  - OpenMP 2019
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -DNDEBUG -DUSE_FBGEMM -DUSE_XNNPACK, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

TorchVision: 0.9.0+cu111
OpenCV: 4.6.0
MMCV: 1.5.0
MMCV Compiler: MSVC 192930138
MMCV CUDA Compiler: 11.1
MMSegmentation: 0.21.1+
------------------------------------------------------------

2023-02-16 23:13:06,336 - mmseg - INFO - Distributed training: False
2023-02-16 23:13:06,509 - mmseg - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
ham_norm_cfg = dict(type='GN', num_groups=32, requires_grad=True)
model = dict(
    type='EncoderDecoder',
    pretrained=
    'E:/5.23/2.13-2.20/2.15/AFFormer-main/pretained_weight/AFFormer_base_ImageNet1k.pth',
    backbone=dict(type='afformer_base', strides=[4, 2, 2, 2]),
    decode_head=dict(
        type='CLS',
        in_channels=[216],
        in_index=[3],
        channels=256,
        aff_channels=256,
        dropout_ratio=0.1,
        num_classes=150,
        norm_cfg=dict(type='GN', num_groups=32, requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),
        aff_kwargs=dict(MD_R=16)),
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'ADE20KDataset'
data_root = 'G:/AI/data/ade20k'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (256, 256)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=True),
    dict(type='Resize', img_scale=(256, 256), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(256, 256), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(256, 256), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
val_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(256, 256),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(256, 256),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='ResizeToMultiple', size_divisor=32),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=8,
    workers_per_gpu=8,
    train=dict(
        type='RepeatDataset',
        times=1,
        dataset=dict(
            type='ADE20KDataset',
            data_root='G:/AI/data/ade20k',
            img_dir='images/training',
            ann_dir='annotations/training',
            pipeline=[
                dict(type='LoadImageFromFile'),
                dict(type='LoadAnnotations', reduce_zero_label=True),
                dict(
                    type='Resize',
                    img_scale=(256, 256),
                    ratio_range=(0.5, 2.0)),
                dict(
                    type='RandomCrop',
                    crop_size=(256, 256),
                    cat_max_ratio=0.75),
                dict(type='RandomFlip', prob=0.5),
                dict(type='PhotoMetricDistortion'),
                dict(
                    type='Normalize',
                    mean=[123.675, 116.28, 103.53],
                    std=[58.395, 57.12, 57.375],
                    to_rgb=True),
                dict(type='Pad', size=(256, 256), pad_val=0, seg_pad_val=255),
                dict(type='DefaultFormatBundle'),
                dict(type='Collect', keys=['img', 'gt_semantic_seg'])
            ])),
    val=dict(
        type='ADE20KDataset',
        data_root='G:/AI/data/ade20k',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(256, 256),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='ADE20KDataset',
        data_root='G:/AI/data/ade20k',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(256, 256),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='ResizeToMultiple', size_divisor=32),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(
    type='AdamW', lr=0.0003, betas=(0.9, 0.999), weight_decay=0.01)
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06,
    power=1.0,
    min_lr=0.0,
    by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=20000)
checkpoint_config = dict(by_epoch=False, interval=2000)
evaluation = dict(interval=2000, metric='mIoU')
find_unused_parameters = True
work_dir = './work_dirs\AFFormer_base_ade20k'
gpu_ids = [0]
auto_resume = False

2023-02-16 23:13:06,509 - mmseg - INFO - Set random seed to 1719938734, deterministic: False
2023-02-16 23:13:06,556 - mmseg - INFO - load checkpoint from local path: E:/5.23/2.13-2.20/2.15/AFFormer-main/pretained_weight/AFFormer_base_ImageNet1k.pth
2023-02-16 23:13:06,619 - mmseg - WARNING - The model and loaded state dict do not match exactly

size mismatch for stem.0.conv.weight: copying a param with shape torch.Size([32, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 3, 3, 3]).
size mismatch for stem.0.bn.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).
size mismatch for stem.0.bn.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).
size mismatch for stem.0.bn.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).
size mismatch for stem.0.bn.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).
size mismatch for stem.1.conv.weight: copying a param with shape torch.Size([64, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 16, 3, 3]).
size mismatch for stem.1.bn.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for stem.1.bn.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for stem.1.bn.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for stem.1.bn.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for patch_embed_stages.0.patch_embeds.0.patch_conv.dwconv.weight: copying a param with shape torch.Size([64, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 1, 3, 3]).
size mismatch for patch_embed_stages.0.patch_embeds.0.patch_conv.pwconv.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 1]).
size mismatch for patch_embed_stages.0.patch_embeds.0.patch_conv.bn.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for patch_embed_stages.0.patch_embeds.0.patch_conv.bn.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for patch_embed_stages.0.patch_embeds.0.patch_conv.bn.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for patch_embed_stages.0.patch_embeds.0.patch_conv.bn.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for patch_embed_stages.0.patch_embeds.1.patch_conv.dwconv.weight: copying a param with shape torch.Size([64, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 1, 3, 3]).
size mismatch for patch_embed_stages.0.patch_embeds.1.patch_conv.pwconv.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 1]).
size mismatch for patch_embed_stages.0.patch_embeds.1.patch_conv.bn.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for patch_embed_stages.0.patch_embeds.1.patch_conv.bn.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for patch_embed_stages.0.patch_embeds.1.patch_conv.bn.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for patch_embed_stages.0.patch_embeds.1.patch_conv.bn.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for mhca_stages.0.Restore.conv1.conv.weight: copying a param with shape torch.Size([32, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([16, 32, 1, 1]).
size mismatch for mhca_stages.0.Restore.conv1.bn.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).
size mismatch for mhca_stages.0.Restore.conv1.bn.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).
size mismatch for mhca_stages.0.Restore.conv1.bn.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).
size mismatch for mhca_stages.0.Restore.conv1.bn.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).
size mismatch for mhca_stages.0.Restore.dwconv.weight: copying a param with shape torch.Size([32, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 1, 3, 3]).
size mismatch for mhca_stages.0.Restore.norm.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).
size mismatch for mhca_stages.0.Restore.norm.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).
size mismatch for mhca_stages.0.Restore.norm.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).
size mismatch for mhca_stages.0.Restore.norm.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).
size mismatch for mhca_stages.0.Restore.conv2.conv.weight: copying a param with shape torch.Size([64, 32, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 16, 1, 1]).
size mismatch for mhca_stages.0.Restore.conv2.bn.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for mhca_stages.0.Restore.conv2.bn.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for mhca_stages.0.Restore.conv2.bn.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for mhca_stages.0.Restore.conv2.bn.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
size mismatch for mhca_stages.0.aggregate.conv.weight: copying a param with shape torch.Size([96, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([96, 32, 1, 1]).
size mismatch for mhca_stages.1.aggregate.conv.weight: copying a param with shape torch.Size([176, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([176, 96, 1, 1]).
size mismatch for mhca_stages.2.aggregate.conv.weight: copying a param with shape torch.Size([216, 352, 1, 1]) from checkpoint, the shape in current model is torch.Size([216, 176, 1, 1]).
size mismatch for mhca_stages.3.aggregate.conv.weight: copying a param with shape torch.Size([216, 432, 1, 1]) from checkpoint, the shape in current model is torch.Size([216, 216, 1, 1]).
unexpected key in source state_dict: cls_head.cls.weight, cls_head.cls.bias

missing keys in source state_dict: mhca_stages.2.mhca_blks.0.MHCA_layers.4.cpe.proj.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.cpe.proj.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.4.crpe.conv_list.0.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.crpe.conv_list.0.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.4.crpe.conv_list.1.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.crpe.conv_list.1.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.4.crpe.conv_list.2.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.crpe.conv_list.2.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.qkv.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.qkv.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.proj.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.proj.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.crpe.conv_list.0.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.crpe.conv_list.0.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.crpe.conv_list.1.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.crpe.conv_list.1.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.crpe.conv_list.2.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.crpe.conv_list.2.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.4.mlp.fc1.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.mlp.fc1.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.4.mlp.dwconv.dwconv.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.mlp.dwconv.dwconv.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.4.mlp.fc2.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.mlp.fc2.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.4.norm1.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.norm1.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.4.norm2.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.4.norm2.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.cpe.proj.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.cpe.proj.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.crpe.conv_list.0.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.crpe.conv_list.0.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.crpe.conv_list.1.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.crpe.conv_list.1.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.crpe.conv_list.2.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.crpe.conv_list.2.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.qkv.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.qkv.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.proj.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.proj.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.crpe.conv_list.0.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.crpe.conv_list.0.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.crpe.conv_list.1.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.crpe.conv_list.1.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.crpe.conv_list.2.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.crpe.conv_list.2.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.mlp.fc1.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.mlp.fc1.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.mlp.dwconv.dwconv.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.mlp.dwconv.dwconv.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.mlp.fc2.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.mlp.fc2.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.norm1.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.norm1.bias, mhca_stages.2.mhca_blks.0.MHCA_layers.5.norm2.weight, mhca_stages.2.mhca_blks.0.MHCA_layers.5.norm2.bias

2023-02-16 23:13:06,619 - mmseg - INFO - initialize CLS with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
Name of parameter - Initialization information

backbone.stem.0.conv.weight - torch.Size([16, 3, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.0.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.0.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.1.conv.weight - torch.Size([32, 16, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.1.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.1.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed_stages.0.patch_embeds.0.patch_conv.dwconv.weight - torch.Size([32, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed_stages.0.patch_embeds.0.patch_conv.pwconv.weight - torch.Size([32, 32, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed_stages.0.patch_embeds.0.patch_conv.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed_stages.0.patch_embeds.0.patch_conv.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed_stages.0.patch_embeds.1.patch_conv.dwconv.weight - torch.Size([32, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed_stages.0.patch_embeds.1.patch_conv.pwconv.weight - torch.Size([32, 32, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed_stages.0.patch_embeds.1.patch_conv.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed_stages.0.patch_embeds.1.patch_conv.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed_stages.1.patch_embeds.0.patch_conv.dwconv.weight - torch.Size([96, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.1.patch_embeds.0.patch_conv.pwconv.weight - torch.Size([96, 96, 1, 1]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.1.patch_embeds.0.patch_conv.bn.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.1.patch_embeds.0.patch_conv.bn.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.1.patch_embeds.1.patch_conv.dwconv.weight - torch.Size([96, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.1.patch_embeds.1.patch_conv.pwconv.weight - torch.Size([96, 96, 1, 1]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.1.patch_embeds.1.patch_conv.bn.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.1.patch_embeds.1.patch_conv.bn.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.2.patch_embeds.0.patch_conv.dwconv.weight - torch.Size([176, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.2.patch_embeds.0.patch_conv.pwconv.weight - torch.Size([176, 176, 1, 1]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.2.patch_embeds.0.patch_conv.bn.weight - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.2.patch_embeds.0.patch_conv.bn.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.2.patch_embeds.1.patch_conv.dwconv.weight - torch.Size([176, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.2.patch_embeds.1.patch_conv.pwconv.weight - torch.Size([176, 176, 1, 1]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.2.patch_embeds.1.patch_conv.bn.weight - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.2.patch_embeds.1.patch_conv.bn.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.3.patch_embeds.0.patch_conv.dwconv.weight - torch.Size([216, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.3.patch_embeds.0.patch_conv.pwconv.weight - torch.Size([216, 216, 1, 1]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.3.patch_embeds.0.patch_conv.bn.weight - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.3.patch_embeds.0.patch_conv.bn.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.3.patch_embeds.1.patch_conv.dwconv.weight - torch.Size([216, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.3.patch_embeds.1.patch_conv.pwconv.weight - torch.Size([216, 216, 1, 1]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.3.patch_embeds.1.patch_conv.bn.weight - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.patch_embed_stages.3.patch_embeds.1.patch_conv.bn.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.0.Restore.conv1.conv.weight - torch.Size([16, 32, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.0.Restore.conv1.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.0.Restore.conv1.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.0.Restore.dwconv.weight - torch.Size([16, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.0.Restore.norm.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.0.Restore.norm.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.0.Restore.conv2.conv.weight - torch.Size([32, 16, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.0.Restore.conv2.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.0.Restore.conv2.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.0.aggregate.conv.weight - torch.Size([96, 32, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.0.aggregate.bn.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.0.aggregate.bn.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.Restore.conv1.conv.weight - torch.Size([48, 96, 1, 1]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.Restore.conv1.bn.weight - torch.Size([48]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.Restore.conv1.bn.bias - torch.Size([48]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.Restore.dwconv.weight - torch.Size([48, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.Restore.norm.weight - torch.Size([48]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.Restore.norm.bias - torch.Size([48]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.Restore.conv2.conv.weight - torch.Size([96, 48, 1, 1]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.Restore.conv2.bn.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.Restore.conv2.bn.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.aggregate.conv.weight - torch.Size([176, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.1.aggregate.bn.weight - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.aggregate.bn.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.cpe.proj.weight - torch.Size([96, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.cpe.proj.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.crpe.conv_list.0.weight - torch.Size([24, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.crpe.conv_list.0.bias - torch.Size([24]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.crpe.conv_list.1.weight - torch.Size([36, 1, 5, 5]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.crpe.conv_list.1.bias - torch.Size([36]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.crpe.conv_list.2.weight - torch.Size([36, 1, 7, 7]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.crpe.conv_list.2.bias - torch.Size([36]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.factoratt_crpe.qkv.weight - torch.Size([288, 96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.factoratt_crpe.qkv.bias - torch.Size([288]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.factoratt_crpe.proj.weight - torch.Size([96, 96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.factoratt_crpe.proj.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.mlp.fc1.weight - torch.Size([192, 96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.mlp.fc1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.mlp.dwconv.dwconv.weight - torch.Size([192, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.mlp.dwconv.dwconv.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.mlp.fc2.weight - torch.Size([96, 192]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.mlp.fc2.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.norm1.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.norm1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.norm2.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.0.norm2.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.factoratt_crpe.qkv.weight - torch.Size([288, 96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.factoratt_crpe.qkv.bias - torch.Size([288]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.factoratt_crpe.proj.weight - torch.Size([96, 96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.factoratt_crpe.proj.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.mlp.fc1.weight - torch.Size([192, 96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.mlp.fc1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.mlp.dwconv.dwconv.weight - torch.Size([192, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.mlp.dwconv.dwconv.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.mlp.fc2.weight - torch.Size([96, 192]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.mlp.fc2.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.norm1.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.norm1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.norm2.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.1.mhca_blks.0.MHCA_layers.1.norm2.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.Restore.conv1.conv.weight - torch.Size([88, 176, 1, 1]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.Restore.conv1.bn.weight - torch.Size([88]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.Restore.conv1.bn.bias - torch.Size([88]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.Restore.dwconv.weight - torch.Size([88, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.Restore.norm.weight - torch.Size([88]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.Restore.norm.bias - torch.Size([88]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.Restore.conv2.conv.weight - torch.Size([176, 88, 1, 1]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.Restore.conv2.bn.weight - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.Restore.conv2.bn.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.aggregate.conv.weight - torch.Size([216, 176, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.aggregate.bn.weight - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.aggregate.bn.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.cpe.proj.weight - torch.Size([176, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.cpe.proj.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.crpe.conv_list.0.weight - torch.Size([44, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.crpe.conv_list.0.bias - torch.Size([44]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.crpe.conv_list.1.weight - torch.Size([66, 1, 5, 5]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.crpe.conv_list.1.bias - torch.Size([66]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.crpe.conv_list.2.weight - torch.Size([66, 1, 7, 7]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.crpe.conv_list.2.bias - torch.Size([66]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.factoratt_crpe.qkv.weight - torch.Size([528, 176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.factoratt_crpe.qkv.bias - torch.Size([528]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.factoratt_crpe.proj.weight - torch.Size([176, 176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.factoratt_crpe.proj.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.mlp.fc1.weight - torch.Size([352, 176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.mlp.fc1.bias - torch.Size([352]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.mlp.dwconv.dwconv.weight - torch.Size([352, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.mlp.dwconv.dwconv.bias - torch.Size([352]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.mlp.fc2.weight - torch.Size([176, 352]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.mlp.fc2.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.norm1.weight - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.norm1.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.norm2.weight - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.0.norm2.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.factoratt_crpe.qkv.weight - torch.Size([528, 176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.factoratt_crpe.qkv.bias - torch.Size([528]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.factoratt_crpe.proj.weight - torch.Size([176, 176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.factoratt_crpe.proj.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.mlp.fc1.weight - torch.Size([352, 176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.mlp.fc1.bias - torch.Size([352]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.mlp.dwconv.dwconv.weight - torch.Size([352, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.mlp.dwconv.dwconv.bias - torch.Size([352]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.mlp.fc2.weight - torch.Size([176, 352]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.mlp.fc2.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.norm1.weight - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.norm1.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.norm2.weight - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.1.norm2.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.factoratt_crpe.qkv.weight - torch.Size([528, 176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.factoratt_crpe.qkv.bias - torch.Size([528]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.factoratt_crpe.proj.weight - torch.Size([176, 176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.factoratt_crpe.proj.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.mlp.fc1.weight - torch.Size([352, 176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.mlp.fc1.bias - torch.Size([352]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.mlp.dwconv.dwconv.weight - torch.Size([352, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.mlp.dwconv.dwconv.bias - torch.Size([352]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.mlp.fc2.weight - torch.Size([176, 352]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.mlp.fc2.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.norm1.weight - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.norm1.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.norm2.weight - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.2.norm2.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.factoratt_crpe.qkv.weight - torch.Size([528, 176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.factoratt_crpe.qkv.bias - torch.Size([528]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.factoratt_crpe.proj.weight - torch.Size([176, 176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.factoratt_crpe.proj.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.mlp.fc1.weight - torch.Size([352, 176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.mlp.fc1.bias - torch.Size([352]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.mlp.dwconv.dwconv.weight - torch.Size([352, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.mlp.dwconv.dwconv.bias - torch.Size([352]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.mlp.fc2.weight - torch.Size([176, 352]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.mlp.fc2.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.norm1.weight - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.norm1.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.norm2.weight - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.3.norm2.bias - torch.Size([176]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.qkv.weight - torch.Size([528, 176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.qkv.bias - torch.Size([528]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.proj.weight - torch.Size([176, 176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.factoratt_crpe.proj.bias - torch.Size([176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.mlp.fc1.weight - torch.Size([352, 176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.mlp.fc1.bias - torch.Size([352]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.mlp.dwconv.dwconv.weight - torch.Size([352, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.mlp.dwconv.dwconv.bias - torch.Size([352]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.mlp.fc2.weight - torch.Size([176, 352]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.mlp.fc2.bias - torch.Size([176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.norm1.weight - torch.Size([176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.norm1.bias - torch.Size([176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.norm2.weight - torch.Size([176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.4.norm2.bias - torch.Size([176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.qkv.weight - torch.Size([528, 176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.qkv.bias - torch.Size([528]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.proj.weight - torch.Size([176, 176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.factoratt_crpe.proj.bias - torch.Size([176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.mlp.fc1.weight - torch.Size([352, 176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.mlp.fc1.bias - torch.Size([352]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.mlp.dwconv.dwconv.weight - torch.Size([352, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.mlp.dwconv.dwconv.bias - torch.Size([352]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.mlp.fc2.weight - torch.Size([176, 352]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.mlp.fc2.bias - torch.Size([176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.norm1.weight - torch.Size([176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.norm1.bias - torch.Size([176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.norm2.weight - torch.Size([176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.2.mhca_blks.0.MHCA_layers.5.norm2.bias - torch.Size([176]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.3.Restore.conv1.conv.weight - torch.Size([108, 216, 1, 1]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.Restore.conv1.bn.weight - torch.Size([108]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.Restore.conv1.bn.bias - torch.Size([108]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.Restore.dwconv.weight - torch.Size([108, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.Restore.norm.weight - torch.Size([108]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.Restore.norm.bias - torch.Size([108]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.Restore.conv2.conv.weight - torch.Size([216, 108, 1, 1]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.Restore.conv2.bn.weight - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.Restore.conv2.bn.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.aggregate.conv.weight - torch.Size([216, 216, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.mhca_stages.3.aggregate.bn.weight - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.aggregate.bn.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.cpe.proj.weight - torch.Size([216, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.cpe.proj.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.crpe.conv_list.0.weight - torch.Size([54, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.crpe.conv_list.0.bias - torch.Size([54]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.crpe.conv_list.1.weight - torch.Size([81, 1, 5, 5]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.crpe.conv_list.1.bias - torch.Size([81]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.crpe.conv_list.2.weight - torch.Size([81, 1, 7, 7]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.crpe.conv_list.2.bias - torch.Size([81]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.factoratt_crpe.qkv.weight - torch.Size([648, 216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.factoratt_crpe.qkv.bias - torch.Size([648]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.factoratt_crpe.proj.weight - torch.Size([216, 216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.factoratt_crpe.proj.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.mlp.fc1.weight - torch.Size([432, 216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.mlp.fc1.bias - torch.Size([432]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.mlp.dwconv.dwconv.weight - torch.Size([432, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.mlp.dwconv.dwconv.bias - torch.Size([432]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.mlp.fc2.weight - torch.Size([216, 432]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.mlp.fc2.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.norm1.weight - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.norm1.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.norm2.weight - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.0.norm2.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.factoratt_crpe.qkv.weight - torch.Size([648, 216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.factoratt_crpe.qkv.bias - torch.Size([648]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.factoratt_crpe.proj.weight - torch.Size([216, 216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.factoratt_crpe.proj.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.mlp.fc1.weight - torch.Size([432, 216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.mlp.fc1.bias - torch.Size([432]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.mlp.dwconv.dwconv.weight - torch.Size([432, 1, 3, 3]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.mlp.dwconv.dwconv.bias - torch.Size([432]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.mlp.fc2.weight - torch.Size([216, 432]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.mlp.fc2.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.norm1.weight - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.norm1.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.norm2.weight - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

backbone.mhca_stages.3.mhca_blks.0.MHCA_layers.1.norm2.bias - torch.Size([216]): 
Initialized by user-defined `init_weights` in afformer_base  

decode_head.conv_seg.weight - torch.Size([150, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([150]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.squeeze.conv.weight - torch.Size([256, 216, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.squeeze.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.squeeze.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.align.conv.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.align.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.align.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2023-02-16 23:13:06,634 - mmseg - INFO - EncoderDecoder(
  (backbone): afformer_base(
    (stem): Sequential(
      (0): Conv2d_BN(
        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act_layer): Hardswish()
      )
      (1): Conv2d_BN(
        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act_layer): Hardswish()
      )
    )
    (patch_embed_stages): ModuleList(
      (0): Patch_Embed_stage(
        (patch_embeds): ModuleList(
          (0): DWCPatchEmbed(
            (patch_conv): DWConv2d_BN(
              (dwconv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
              (pwconv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Hardswish()
            )
          )
          (1): DWCPatchEmbed(
            (patch_conv): DWConv2d_BN(
              (dwconv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
              (pwconv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Hardswish()
            )
          )
        )
      )
      (1): Patch_Embed_stage(
        (patch_embeds): ModuleList(
          (0): DWCPatchEmbed(
            (patch_conv): DWConv2d_BN(
              (dwconv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
              (pwconv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Hardswish()
            )
          )
          (1): DWCPatchEmbed(
            (patch_conv): DWConv2d_BN(
              (dwconv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (pwconv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Hardswish()
            )
          )
        )
      )
      (2): Patch_Embed_stage(
        (patch_embeds): ModuleList(
          (0): DWCPatchEmbed(
            (patch_conv): DWConv2d_BN(
              (dwconv): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176, bias=False)
              (pwconv): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Hardswish()
            )
          )
          (1): DWCPatchEmbed(
            (patch_conv): DWConv2d_BN(
              (dwconv): Conv2d(176, 176, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=176, bias=False)
              (pwconv): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Hardswish()
            )
          )
        )
      )
      (3): Patch_Embed_stage(
        (patch_embeds): ModuleList(
          (0): DWCPatchEmbed(
            (patch_conv): DWConv2d_BN(
              (dwconv): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216, bias=False)
              (pwconv): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Hardswish()
            )
          )
          (1): DWCPatchEmbed(
            (patch_conv): DWConv2d_BN(
              (dwconv): Conv2d(216, 216, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=216, bias=False)
              (pwconv): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act): Hardswish()
            )
          )
        )
      )
    )
    (mhca_stages): ModuleList(
      (0): MHCA_stage(
        (Restore): Restore(
          (conv1): Conv2d_BN(
            (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_layer): Hardswish()
          )
          (dwconv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
          (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Hardswish()
          (conv2): Conv2d_BN(
            (conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_layer): Identity()
          )
        )
        (aggregate): Conv2d_BN(
          (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_layer): Hardswish()
        )
      )
      (1): MHCA_stage(
        (Restore): Restore(
          (conv1): Conv2d_BN(
            (conv): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_layer): Hardswish()
          )
          (dwconv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
          (norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Hardswish()
          (conv2): Conv2d_BN(
            (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_layer): Identity()
          )
        )
        (aggregate): Conv2d_BN(
          (conv): Conv2d(96, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_layer): Hardswish()
        )
        (mhca_blks): ModuleList(
          (0): MHCAEncoder(
            (cpe): ConvPosEnc(
              (proj): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
            )
            (crpe): FilterModule(
              (conv_list): ModuleList(
                (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
                (1): Conv2d(36, 36, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=36)
                (2): Conv2d(36, 36, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=36)
              )
              (LP): LowPassModule(
                (stages): ModuleList(
                  (0): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=(1, 1))
                  )
                  (1): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=(2, 2))
                  )
                  (2): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=(3, 3))
                  )
                  (3): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=(6, 6))
                  )
                )
                (relu): ReLU()
              )
            )
            (MHCA_layers): ModuleList(
              (0): MHCABlock(
                (cpe): ConvPosEnc(
                  (proj): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
                )
                (crpe): FilterModule(
                  (conv_list): ModuleList(
                    (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
                    (1): Conv2d(36, 36, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=36)
                    (2): Conv2d(36, 36, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=36)
                  )
                  (LP): LowPassModule(
                    (stages): ModuleList(
                      (0): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(1, 1))
                      )
                      (1): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(2, 2))
                      )
                      (2): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(3, 3))
                      )
                      (3): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(6, 6))
                      )
                    )
                    (relu): ReLU()
                  )
                )
                (factoratt_crpe): Frequency_FilterModule(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (crpe): FilterModule(
                    (conv_list): ModuleList(
                      (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
                      (1): Conv2d(36, 36, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=36)
                      (2): Conv2d(36, 36, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=36)
                    )
                    (LP): LowPassModule(
                      (stages): ModuleList(
                        (0): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(1, 1))
                        )
                        (1): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(2, 2))
                        )
                        (2): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(3, 3))
                        )
                        (3): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(6, 6))
                        )
                      )
                      (relu): ReLU()
                    )
                  )
                )
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=192, bias=True)
                  (dwconv): DWConv(
                    (dwconv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
                  )
                  (act): GELU()
                  (fc2): Linear(in_features=192, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (drop_path): Identity()
                (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
                (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
              )
              (1): MHCABlock(
                (cpe): ConvPosEnc(
                  (proj): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
                )
                (crpe): FilterModule(
                  (conv_list): ModuleList(
                    (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
                    (1): Conv2d(36, 36, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=36)
                    (2): Conv2d(36, 36, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=36)
                  )
                  (LP): LowPassModule(
                    (stages): ModuleList(
                      (0): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(1, 1))
                      )
                      (1): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(2, 2))
                      )
                      (2): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(3, 3))
                      )
                      (3): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(6, 6))
                      )
                    )
                    (relu): ReLU()
                  )
                )
                (factoratt_crpe): Frequency_FilterModule(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (crpe): FilterModule(
                    (conv_list): ModuleList(
                      (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
                      (1): Conv2d(36, 36, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=36)
                      (2): Conv2d(36, 36, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=36)
                    )
                    (LP): LowPassModule(
                      (stages): ModuleList(
                        (0): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(1, 1))
                        )
                        (1): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(2, 2))
                        )
                        (2): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(3, 3))
                        )
                        (3): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(6, 6))
                        )
                      )
                      (relu): ReLU()
                    )
                  )
                )
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=192, bias=True)
                  (dwconv): DWConv(
                    (dwconv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
                  )
                  (act): GELU()
                  (fc2): Linear(in_features=192, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (drop_path): Identity()
                (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
                (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
              )
            )
          )
        )
      )
      (2): MHCA_stage(
        (Restore): Restore(
          (conv1): Conv2d_BN(
            (conv): Conv2d(176, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_layer): Hardswish()
          )
          (dwconv): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)
          (norm): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Hardswish()
          (conv2): Conv2d_BN(
            (conv): Conv2d(88, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_layer): Identity()
          )
        )
        (aggregate): Conv2d_BN(
          (conv): Conv2d(176, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_layer): Hardswish()
        )
        (mhca_blks): ModuleList(
          (0): MHCAEncoder(
            (cpe): ConvPosEnc(
              (proj): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176)
            )
            (crpe): FilterModule(
              (conv_list): ModuleList(
                (0): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=44)
                (1): Conv2d(66, 66, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=66)
                (2): Conv2d(66, 66, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=66)
              )
              (LP): LowPassModule(
                (stages): ModuleList(
                  (0): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=(1, 1))
                  )
                  (1): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=(2, 2))
                  )
                  (2): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=(3, 3))
                  )
                  (3): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=(6, 6))
                  )
                )
                (relu): ReLU()
              )
            )
            (MHCA_layers): ModuleList(
              (0): MHCABlock(
                (cpe): ConvPosEnc(
                  (proj): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176)
                )
                (crpe): FilterModule(
                  (conv_list): ModuleList(
                    (0): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=44)
                    (1): Conv2d(66, 66, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=66)
                    (2): Conv2d(66, 66, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=66)
                  )
                  (LP): LowPassModule(
                    (stages): ModuleList(
                      (0): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(1, 1))
                      )
                      (1): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(2, 2))
                      )
                      (2): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(3, 3))
                      )
                      (3): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(6, 6))
                      )
                    )
                    (relu): ReLU()
                  )
                )
                (factoratt_crpe): Frequency_FilterModule(
                  (qkv): Linear(in_features=176, out_features=528, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=176, out_features=176, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (crpe): FilterModule(
                    (conv_list): ModuleList(
                      (0): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=44)
                      (1): Conv2d(66, 66, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=66)
                      (2): Conv2d(66, 66, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=66)
                    )
                    (LP): LowPassModule(
                      (stages): ModuleList(
                        (0): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(1, 1))
                        )
                        (1): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(2, 2))
                        )
                        (2): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(3, 3))
                        )
                        (3): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(6, 6))
                        )
                      )
                      (relu): ReLU()
                    )
                  )
                )
                (mlp): Mlp(
                  (fc1): Linear(in_features=176, out_features=352, bias=True)
                  (dwconv): DWConv(
                    (dwconv): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352)
                  )
                  (act): GELU()
                  (fc2): Linear(in_features=352, out_features=176, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (drop_path): Identity()
                (norm1): LayerNorm((176,), eps=1e-06, elementwise_affine=True)
                (norm2): LayerNorm((176,), eps=1e-06, elementwise_affine=True)
              )
              (1): MHCABlock(
                (cpe): ConvPosEnc(
                  (proj): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176)
                )
                (crpe): FilterModule(
                  (conv_list): ModuleList(
                    (0): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=44)
                    (1): Conv2d(66, 66, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=66)
                    (2): Conv2d(66, 66, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=66)
                  )
                  (LP): LowPassModule(
                    (stages): ModuleList(
                      (0): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(1, 1))
                      )
                      (1): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(2, 2))
                      )
                      (2): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(3, 3))
                      )
                      (3): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(6, 6))
                      )
                    )
                    (relu): ReLU()
                  )
                )
                (factoratt_crpe): Frequency_FilterModule(
                  (qkv): Linear(in_features=176, out_features=528, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=176, out_features=176, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (crpe): FilterModule(
                    (conv_list): ModuleList(
                      (0): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=44)
                      (1): Conv2d(66, 66, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=66)
                      (2): Conv2d(66, 66, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=66)
                    )
                    (LP): LowPassModule(
                      (stages): ModuleList(
                        (0): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(1, 1))
                        )
                        (1): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(2, 2))
                        )
                        (2): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(3, 3))
                        )
                        (3): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(6, 6))
                        )
                      )
                      (relu): ReLU()
                    )
                  )
                )
                (mlp): Mlp(
                  (fc1): Linear(in_features=176, out_features=352, bias=True)
                  (dwconv): DWConv(
                    (dwconv): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352)
                  )
                  (act): GELU()
                  (fc2): Linear(in_features=352, out_features=176, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (drop_path): Identity()
                (norm1): LayerNorm((176,), eps=1e-06, elementwise_affine=True)
                (norm2): LayerNorm((176,), eps=1e-06, elementwise_affine=True)
              )
              (2): MHCABlock(
                (cpe): ConvPosEnc(
                  (proj): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176)
                )
                (crpe): FilterModule(
                  (conv_list): ModuleList(
                    (0): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=44)
                    (1): Conv2d(66, 66, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=66)
                    (2): Conv2d(66, 66, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=66)
                  )
                  (LP): LowPassModule(
                    (stages): ModuleList(
                      (0): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(1, 1))
                      )
                      (1): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(2, 2))
                      )
                      (2): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(3, 3))
                      )
                      (3): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(6, 6))
                      )
                    )
                    (relu): ReLU()
                  )
                )
                (factoratt_crpe): Frequency_FilterModule(
                  (qkv): Linear(in_features=176, out_features=528, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=176, out_features=176, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (crpe): FilterModule(
                    (conv_list): ModuleList(
                      (0): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=44)
                      (1): Conv2d(66, 66, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=66)
                      (2): Conv2d(66, 66, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=66)
                    )
                    (LP): LowPassModule(
                      (stages): ModuleList(
                        (0): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(1, 1))
                        )
                        (1): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(2, 2))
                        )
                        (2): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(3, 3))
                        )
                        (3): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(6, 6))
                        )
                      )
                      (relu): ReLU()
                    )
                  )
                )
                (mlp): Mlp(
                  (fc1): Linear(in_features=176, out_features=352, bias=True)
                  (dwconv): DWConv(
                    (dwconv): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352)
                  )
                  (act): GELU()
                  (fc2): Linear(in_features=352, out_features=176, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (drop_path): Identity()
                (norm1): LayerNorm((176,), eps=1e-06, elementwise_affine=True)
                (norm2): LayerNorm((176,), eps=1e-06, elementwise_affine=True)
              )
              (3): MHCABlock(
                (cpe): ConvPosEnc(
                  (proj): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176)
                )
                (crpe): FilterModule(
                  (conv_list): ModuleList(
                    (0): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=44)
                    (1): Conv2d(66, 66, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=66)
                    (2): Conv2d(66, 66, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=66)
                  )
                  (LP): LowPassModule(
                    (stages): ModuleList(
                      (0): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(1, 1))
                      )
                      (1): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(2, 2))
                      )
                      (2): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(3, 3))
                      )
                      (3): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(6, 6))
                      )
                    )
                    (relu): ReLU()
                  )
                )
                (factoratt_crpe): Frequency_FilterModule(
                  (qkv): Linear(in_features=176, out_features=528, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=176, out_features=176, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (crpe): FilterModule(
                    (conv_list): ModuleList(
                      (0): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=44)
                      (1): Conv2d(66, 66, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=66)
                      (2): Conv2d(66, 66, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=66)
                    )
                    (LP): LowPassModule(
                      (stages): ModuleList(
                        (0): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(1, 1))
                        )
                        (1): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(2, 2))
                        )
                        (2): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(3, 3))
                        )
                        (3): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(6, 6))
                        )
                      )
                      (relu): ReLU()
                    )
                  )
                )
                (mlp): Mlp(
                  (fc1): Linear(in_features=176, out_features=352, bias=True)
                  (dwconv): DWConv(
                    (dwconv): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352)
                  )
                  (act): GELU()
                  (fc2): Linear(in_features=352, out_features=176, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (drop_path): Identity()
                (norm1): LayerNorm((176,), eps=1e-06, elementwise_affine=True)
                (norm2): LayerNorm((176,), eps=1e-06, elementwise_affine=True)
              )
              (4): MHCABlock(
                (cpe): ConvPosEnc(
                  (proj): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176)
                )
                (crpe): FilterModule(
                  (conv_list): ModuleList(
                    (0): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=44)
                    (1): Conv2d(66, 66, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=66)
                    (2): Conv2d(66, 66, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=66)
                  )
                  (LP): LowPassModule(
                    (stages): ModuleList(
                      (0): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(1, 1))
                      )
                      (1): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(2, 2))
                      )
                      (2): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(3, 3))
                      )
                      (3): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(6, 6))
                      )
                    )
                    (relu): ReLU()
                  )
                )
                (factoratt_crpe): Frequency_FilterModule(
                  (qkv): Linear(in_features=176, out_features=528, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=176, out_features=176, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (crpe): FilterModule(
                    (conv_list): ModuleList(
                      (0): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=44)
                      (1): Conv2d(66, 66, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=66)
                      (2): Conv2d(66, 66, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=66)
                    )
                    (LP): LowPassModule(
                      (stages): ModuleList(
                        (0): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(1, 1))
                        )
                        (1): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(2, 2))
                        )
                        (2): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(3, 3))
                        )
                        (3): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(6, 6))
                        )
                      )
                      (relu): ReLU()
                    )
                  )
                )
                (mlp): Mlp(
                  (fc1): Linear(in_features=176, out_features=352, bias=True)
                  (dwconv): DWConv(
                    (dwconv): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352)
                  )
                  (act): GELU()
                  (fc2): Linear(in_features=352, out_features=176, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (drop_path): Identity()
                (norm1): LayerNorm((176,), eps=1e-06, elementwise_affine=True)
                (norm2): LayerNorm((176,), eps=1e-06, elementwise_affine=True)
              )
              (5): MHCABlock(
                (cpe): ConvPosEnc(
                  (proj): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176)
                )
                (crpe): FilterModule(
                  (conv_list): ModuleList(
                    (0): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=44)
                    (1): Conv2d(66, 66, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=66)
                    (2): Conv2d(66, 66, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=66)
                  )
                  (LP): LowPassModule(
                    (stages): ModuleList(
                      (0): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(1, 1))
                      )
                      (1): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(2, 2))
                      )
                      (2): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(3, 3))
                      )
                      (3): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(6, 6))
                      )
                    )
                    (relu): ReLU()
                  )
                )
                (factoratt_crpe): Frequency_FilterModule(
                  (qkv): Linear(in_features=176, out_features=528, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=176, out_features=176, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (crpe): FilterModule(
                    (conv_list): ModuleList(
                      (0): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=44)
                      (1): Conv2d(66, 66, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=66)
                      (2): Conv2d(66, 66, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=66)
                    )
                    (LP): LowPassModule(
                      (stages): ModuleList(
                        (0): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(1, 1))
                        )
                        (1): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(2, 2))
                        )
                        (2): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(3, 3))
                        )
                        (3): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(6, 6))
                        )
                      )
                      (relu): ReLU()
                    )
                  )
                )
                (mlp): Mlp(
                  (fc1): Linear(in_features=176, out_features=352, bias=True)
                  (dwconv): DWConv(
                    (dwconv): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352)
                  )
                  (act): GELU()
                  (fc2): Linear(in_features=352, out_features=176, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (drop_path): Identity()
                (norm1): LayerNorm((176,), eps=1e-06, elementwise_affine=True)
                (norm2): LayerNorm((176,), eps=1e-06, elementwise_affine=True)
              )
            )
          )
        )
      )
      (3): MHCA_stage(
        (Restore): Restore(
          (conv1): Conv2d_BN(
            (conv): Conv2d(216, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_layer): Hardswish()
          )
          (dwconv): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=108, bias=False)
          (norm): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): Hardswish()
          (conv2): Conv2d_BN(
            (conv): Conv2d(108, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act_layer): Identity()
          )
        )
        (aggregate): Conv2d_BN(
          (conv): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act_layer): Hardswish()
        )
        (mhca_blks): ModuleList(
          (0): MHCAEncoder(
            (cpe): ConvPosEnc(
              (proj): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216)
            )
            (crpe): FilterModule(
              (conv_list): ModuleList(
                (0): Conv2d(54, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=54)
                (1): Conv2d(81, 81, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=81)
                (2): Conv2d(81, 81, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=81)
              )
              (LP): LowPassModule(
                (stages): ModuleList(
                  (0): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=(1, 1))
                  )
                  (1): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=(2, 2))
                  )
                  (2): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=(3, 3))
                  )
                  (3): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=(6, 6))
                  )
                )
                (relu): ReLU()
              )
            )
            (MHCA_layers): ModuleList(
              (0): MHCABlock(
                (cpe): ConvPosEnc(
                  (proj): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216)
                )
                (crpe): FilterModule(
                  (conv_list): ModuleList(
                    (0): Conv2d(54, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=54)
                    (1): Conv2d(81, 81, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=81)
                    (2): Conv2d(81, 81, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=81)
                  )
                  (LP): LowPassModule(
                    (stages): ModuleList(
                      (0): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(1, 1))
                      )
                      (1): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(2, 2))
                      )
                      (2): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(3, 3))
                      )
                      (3): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(6, 6))
                      )
                    )
                    (relu): ReLU()
                  )
                )
                (factoratt_crpe): Frequency_FilterModule(
                  (qkv): Linear(in_features=216, out_features=648, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=216, out_features=216, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (crpe): FilterModule(
                    (conv_list): ModuleList(
                      (0): Conv2d(54, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=54)
                      (1): Conv2d(81, 81, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=81)
                      (2): Conv2d(81, 81, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=81)
                    )
                    (LP): LowPassModule(
                      (stages): ModuleList(
                        (0): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(1, 1))
                        )
                        (1): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(2, 2))
                        )
                        (2): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(3, 3))
                        )
                        (3): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(6, 6))
                        )
                      )
                      (relu): ReLU()
                    )
                  )
                )
                (mlp): Mlp(
                  (fc1): Linear(in_features=216, out_features=432, bias=True)
                  (dwconv): DWConv(
                    (dwconv): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432)
                  )
                  (act): GELU()
                  (fc2): Linear(in_features=432, out_features=216, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (drop_path): Identity()
                (norm1): LayerNorm((216,), eps=1e-06, elementwise_affine=True)
                (norm2): LayerNorm((216,), eps=1e-06, elementwise_affine=True)
              )
              (1): MHCABlock(
                (cpe): ConvPosEnc(
                  (proj): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=216)
                )
                (crpe): FilterModule(
                  (conv_list): ModuleList(
                    (0): Conv2d(54, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=54)
                    (1): Conv2d(81, 81, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=81)
                    (2): Conv2d(81, 81, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=81)
                  )
                  (LP): LowPassModule(
                    (stages): ModuleList(
                      (0): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(1, 1))
                      )
                      (1): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(2, 2))
                      )
                      (2): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(3, 3))
                      )
                      (3): Sequential(
                        (0): AdaptiveAvgPool2d(output_size=(6, 6))
                      )
                    )
                    (relu): ReLU()
                  )
                )
                (factoratt_crpe): Frequency_FilterModule(
                  (qkv): Linear(in_features=216, out_features=648, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=216, out_features=216, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (crpe): FilterModule(
                    (conv_list): ModuleList(
                      (0): Conv2d(54, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=54)
                      (1): Conv2d(81, 81, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=81)
                      (2): Conv2d(81, 81, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=81)
                    )
                    (LP): LowPassModule(
                      (stages): ModuleList(
                        (0): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(1, 1))
                        )
                        (1): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(2, 2))
                        )
                        (2): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(3, 3))
                        )
                        (3): Sequential(
                          (0): AdaptiveAvgPool2d(output_size=(6, 6))
                        )
                      )
                      (relu): ReLU()
                    )
                  )
                )
                (mlp): Mlp(
                  (fc1): Linear(in_features=216, out_features=432, bias=True)
                  (dwconv): DWConv(
                    (dwconv): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432)
                  )
                  (act): GELU()
                  (fc2): Linear(in_features=432, out_features=216, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (drop_path): Identity()
                (norm1): LayerNorm((216,), eps=1e-06, elementwise_affine=True)
                (norm2): LayerNorm((216,), eps=1e-06, elementwise_affine=True)
              )
            )
          )
        )
      )
    )
  )
  init_cfg=E:/5.23/2.13-2.20/2.15/AFFormer-main/pretained_weight/AFFormer_base_ImageNet1k.pth
  (decode_head): CLS(
    input_transform=multiple_select, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss()
    (conv_seg): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (squeeze): ConvModule(
      (conv): Conv2d(216, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (gn): GroupNorm(32, 256, eps=1e-05, affine=True)
      (activate): ReLU(inplace=True)
    )
    (align): ConvModule(
      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (gn): GroupNorm(32, 256, eps=1e-05, affine=True)
      (activate): ReLU(inplace=True)
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
)
2023-02-16 23:13:06,682 - mmseg - INFO - Loaded 960 images
2023-02-16 23:13:08,078 - mmseg - INFO - Loaded 88 images
2023-02-16 23:13:08,078 - mmseg - INFO - Start running, host: 赵家琪@LAPTOP-1ADKIJ7N, work_dir: E:\5.23\2.13-2.20\2.15\AFFormer-main\tools\work_dirs\AFFormer_base_ade20k
2023-02-16 23:13:08,078 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-02-16 23:13:08,078 - mmseg - INFO - workflow: [('train', 1)], max: 20000 iters
2023-02-16 23:13:08,078 - mmseg - INFO - Checkpoints will be saved to E:\5.23\2.13-2.20\2.15\AFFormer-main\tools\work_dirs\AFFormer_base_ade20k by HardDiskBackend.
2023-02-16 23:13:33,484 - mmseg - INFO - Iter [50/20000]	lr: 9.776e-06, eta: 1:09:12, time: 0.208, data_time: 0.006, memory: 1942, decode.loss_ce: 3.6958, decode.acc_seg: 0.2552, loss: 3.6958
2023-02-16 23:13:41,264 - mmseg - INFO - Iter [100/20000]	lr: 1.970e-05, eta: 1:00:22, time: 0.156, data_time: 0.005, memory: 1942, decode.loss_ce: 3.6634, decode.acc_seg: 2.3996, loss: 3.6634
2023-02-16 23:13:51,284 - mmseg - INFO - Iter [150/20000]	lr: 2.958e-05, eta: 1:02:14, time: 0.200, data_time: 0.048, memory: 1942, decode.loss_ce: 3.5910, decode.acc_seg: 10.5137, loss: 3.5910
2023-02-16 23:13:59,156 - mmseg - INFO - Iter [200/20000]	lr: 3.940e-05, eta: 0:59:33, time: 0.157, data_time: 0.006, memory: 1942, decode.loss_ce: 3.3269, decode.acc_seg: 22.3399, loss: 3.3269
2023-02-16 23:14:09,150 - mmseg - INFO - Iter [250/20000]	lr: 4.918e-05, eta: 1:00:40, time: 0.200, data_time: 0.049, memory: 1942, decode.loss_ce: 3.0430, decode.acc_seg: 26.2928, loss: 3.0430
2023-02-16 23:14:16,893 - mmseg - INFO - Iter [300/20000]	lr: 5.891e-05, eta: 0:58:54, time: 0.155, data_time: 0.004, memory: 1942, decode.loss_ce: 2.8392, decode.acc_seg: 32.9063, loss: 2.8392
2023-02-16 23:14:24,593 - mmseg - INFO - Iter [350/20000]	lr: 6.858e-05, eta: 0:57:34, time: 0.154, data_time: 0.005, memory: 1942, decode.loss_ce: 2.4727, decode.acc_seg: 27.5552, loss: 2.4727
2023-02-16 23:14:34,657 - mmseg - INFO - Iter [400/20000]	lr: 7.821e-05, eta: 0:58:28, time: 0.201, data_time: 0.047, memory: 1942, decode.loss_ce: 2.3925, decode.acc_seg: 34.0223, loss: 2.3925
2023-02-16 23:14:42,295 - mmseg - INFO - Iter [450/20000]	lr: 8.778e-05, eta: 0:57:22, time: 0.153, data_time: 0.005, memory: 1942, decode.loss_ce: 2.1697, decode.acc_seg: 31.3807, loss: 2.1697
2023-02-16 23:14:52,233 - mmseg - INFO - Iter [500/20000]	lr: 9.731e-05, eta: 0:57:57, time: 0.199, data_time: 0.048, memory: 1942, decode.loss_ce: 2.1724, decode.acc_seg: 33.0671, loss: 2.1724
2023-02-16 23:14:59,893 - mmseg - INFO - Iter [550/20000]	lr: 1.068e-04, eta: 0:57:04, time: 0.153, data_time: 0.006, memory: 1942, decode.loss_ce: 1.7965, decode.acc_seg: 38.1850, loss: 1.7965
2023-02-16 23:15:07,815 - mmseg - INFO - Iter [600/20000]	lr: 1.162e-04, eta: 0:56:27, time: 0.158, data_time: 0.006, memory: 1942, decode.loss_ce: 2.1534, decode.acc_seg: 29.6548, loss: 2.1534
2023-02-16 23:15:17,814 - mmseg - INFO - Iter [650/20000]	lr: 1.256e-04, eta: 0:56:56, time: 0.200, data_time: 0.048, memory: 1942, decode.loss_ce: 1.8453, decode.acc_seg: 38.3200, loss: 1.8453
2023-02-16 23:15:25,647 - mmseg - INFO - Iter [700/20000]	lr: 1.349e-04, eta: 0:56:19, time: 0.157, data_time: 0.008, memory: 1942, decode.loss_ce: 1.9150, decode.acc_seg: 35.7493, loss: 1.9150
2023-02-16 23:15:35,595 - mmseg - INFO - Iter [750/20000]	lr: 1.442e-04, eta: 0:56:41, time: 0.199, data_time: 0.048, memory: 1942, decode.loss_ce: 2.0690, decode.acc_seg: 34.8420, loss: 2.0690
2023-02-16 23:15:43,377 - mmseg - INFO - Iter [800/20000]	lr: 1.534e-04, eta: 0:56:07, time: 0.156, data_time: 0.007, memory: 1942, decode.loss_ce: 1.7531, decode.acc_seg: 41.1254, loss: 1.7531
2023-02-16 23:15:53,595 - mmseg - INFO - Iter [850/20000]	lr: 1.626e-04, eta: 0:56:31, time: 0.204, data_time: 0.048, memory: 1942, decode.loss_ce: 1.9437, decode.acc_seg: 36.1429, loss: 1.9437
2023-02-16 23:16:01,565 - mmseg - INFO - Iter [900/20000]	lr: 1.717e-04, eta: 0:56:03, time: 0.159, data_time: 0.007, memory: 1942, decode.loss_ce: 1.6077, decode.acc_seg: 44.6369, loss: 1.6077
2023-02-16 23:16:09,551 - mmseg - INFO - Iter [950/20000]	lr: 1.808e-04, eta: 0:55:38, time: 0.160, data_time: 0.005, memory: 1942, decode.loss_ce: 1.8775, decode.acc_seg: 37.9811, loss: 1.8775
2023-02-16 23:16:19,682 - mmseg - INFO - Exp name: AFFormer_base_ade20k.py
2023-02-16 23:16:19,682 - mmseg - INFO - Iter [1000/20000]	lr: 1.898e-04, eta: 0:55:55, time: 0.203, data_time: 0.047, memory: 1942, decode.loss_ce: 1.9306, decode.acc_seg: 38.1535, loss: 1.9306
2023-02-16 23:16:27,491 - mmseg - INFO - Iter [1050/20000]	lr: 1.988e-04, eta: 0:55:28, time: 0.156, data_time: 0.003, memory: 1942, decode.loss_ce: 1.7828, decode.acc_seg: 43.2393, loss: 1.7828
2023-02-16 23:16:37,475 - mmseg - INFO - Iter [1100/20000]	lr: 2.077e-04, eta: 0:55:40, time: 0.200, data_time: 0.047, memory: 1942, decode.loss_ce: 1.7884, decode.acc_seg: 39.0126, loss: 1.7884
2023-02-16 23:16:45,223 - mmseg - INFO - Iter [1150/20000]	lr: 2.166e-04, eta: 0:55:13, time: 0.155, data_time: 0.006, memory: 1942, decode.loss_ce: 1.5148, decode.acc_seg: 49.3860, loss: 1.5148
2023-02-16 23:16:52,941 - mmseg - INFO - Iter [1200/20000]	lr: 2.254e-04, eta: 0:54:48, time: 0.154, data_time: 0.008, memory: 1942, decode.loss_ce: 1.9246, decode.acc_seg: 35.6158, loss: 1.9246
2023-02-16 23:17:02,932 - mmseg - INFO - Iter [1250/20000]	lr: 2.342e-04, eta: 0:54:58, time: 0.200, data_time: 0.048, memory: 1942, decode.loss_ce: 1.7197, decode.acc_seg: 43.0675, loss: 1.7197
2023-02-16 23:17:10,701 - mmseg - INFO - Iter [1300/20000]	lr: 2.429e-04, eta: 0:54:34, time: 0.155, data_time: 0.006, memory: 1942, decode.loss_ce: 1.7718, decode.acc_seg: 42.5035, loss: 1.7718
2023-02-16 23:17:20,709 - mmseg - INFO - Iter [1350/20000]	lr: 2.516e-04, eta: 0:54:43, time: 0.200, data_time: 0.049, memory: 1942, decode.loss_ce: 1.9377, decode.acc_seg: 38.5935, loss: 1.9377
2023-02-16 23:17:28,531 - mmseg - INFO - Iter [1400/20000]	lr: 2.602e-04, eta: 0:54:21, time: 0.156, data_time: 0.006, memory: 1942, decode.loss_ce: 1.6610, decode.acc_seg: 47.5188, loss: 1.6610
2023-02-16 23:17:38,704 - mmseg - INFO - Iter [1450/20000]	lr: 2.688e-04, eta: 0:54:30, time: 0.203, data_time: 0.050, memory: 1942, decode.loss_ce: 1.7251, decode.acc_seg: 39.3467, loss: 1.7251
2023-02-16 23:17:46,404 - mmseg - INFO - Iter [1500/20000]	lr: 2.773e-04, eta: 0:54:07, time: 0.154, data_time: 0.006, memory: 1942, decode.loss_ce: 1.5726, decode.acc_seg: 47.7975, loss: 1.5726
2023-02-16 23:17:54,354 - mmseg - INFO - Iter [1550/20000]	lr: 2.768e-04, eta: 0:53:49, time: 0.159, data_time: 0.005, memory: 1942, decode.loss_ce: 1.6895, decode.acc_seg: 41.8486, loss: 1.6895
2023-02-16 23:18:04,580 - mmseg - INFO - Iter [1600/20000]	lr: 2.760e-04, eta: 0:53:57, time: 0.205, data_time: 0.049, memory: 1942, decode.loss_ce: 1.8442, decode.acc_seg: 40.1324, loss: 1.8442
2023-02-16 23:18:12,369 - mmseg - INFO - Iter [1650/20000]	lr: 2.753e-04, eta: 0:53:37, time: 0.156, data_time: 0.009, memory: 1942, decode.loss_ce: 1.5774, decode.acc_seg: 47.7187, loss: 1.5774
2023-02-16 23:18:22,388 - mmseg - INFO - Iter [1700/20000]	lr: 2.745e-04, eta: 0:53:42, time: 0.200, data_time: 0.048, memory: 1942, decode.loss_ce: 1.7393, decode.acc_seg: 41.5227, loss: 1.7393
2023-02-16 23:18:30,245 - mmseg - INFO - Iter [1750/20000]	lr: 2.738e-04, eta: 0:53:23, time: 0.157, data_time: 0.005, memory: 1942, decode.loss_ce: 1.3541, decode.acc_seg: 54.6897, loss: 1.3541
2023-02-16 23:18:37,977 - mmseg - INFO - Iter [1800/20000]	lr: 2.730e-04, eta: 0:53:04, time: 0.155, data_time: 0.006, memory: 1942, decode.loss_ce: 1.7790, decode.acc_seg: 38.2490, loss: 1.7790
2023-02-16 23:18:48,108 - mmseg - INFO - Iter [1850/20000]	lr: 2.723e-04, eta: 0:53:08, time: 0.203, data_time: 0.049, memory: 1942, decode.loss_ce: 1.5971, decode.acc_seg: 46.8622, loss: 1.5971
2023-02-16 23:18:55,836 - mmseg - INFO - Iter [1900/20000]	lr: 2.715e-04, eta: 0:52:49, time: 0.154, data_time: 0.008, memory: 1942, decode.loss_ce: 1.5706, decode.acc_seg: 45.9041, loss: 1.5706
2023-02-16 23:19:05,942 - mmseg - INFO - Iter [1950/20000]	lr: 2.708e-04, eta: 0:52:53, time: 0.202, data_time: 0.049, memory: 1942, decode.loss_ce: 1.7695, decode.acc_seg: 41.2351, loss: 1.7695
2023-02-16 23:19:13,849 - mmseg - INFO - Saving checkpoint at 2000 iterations
2023-02-16 23:19:14,083 - mmseg - INFO - Exp name: AFFormer_base_ade20k.py
2023-02-16 23:19:14,083 - mmseg - INFO - Iter [2000/20000]	lr: 2.700e-04, eta: 0:52:39, time: 0.163, data_time: 0.005, memory: 1942, decode.loss_ce: 1.4700, decode.acc_seg: 51.4841, loss: 1.4700
